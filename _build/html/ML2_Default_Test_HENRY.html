
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Codificación de variables categóricas &#8212; Parcial 2</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ML2_Default_Test_HENRY';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Ejercicio 3" href="Ejercicio3.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Parcial 2 - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Parcial 2 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Parcial 2
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="windspeedEDA.html">Velocidad del viento</a></li>




<li class="toctree-l1"><a class="reference internal" href="EDA_Deafault_Henry.html">Parcial práctico 2 Machine Learning</a></li>


<li class="toctree-l1"><a class="reference internal" href="Ejercicio3.html">Ejercicio 3</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Codificación de variables categóricas</a></li>




</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FML2_Default_Test_HENRY.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/ML2_Default_Test_HENRY.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Codificación de variables categóricas</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Codificación de variables categóricas</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-de-metricas">Definición de métricas</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#exploracion-inicial-de-variable-respuesta">Exploración inicial de variable respuesta</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-con-adasyn">Modelo con ADASYN</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelamiento-sin-adasyn">Modelamiento sin Adasyn</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>Modelo Machine Learning - Default</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">statsmodels</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">sklearn</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">dask</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">tabulate</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">missingno</span> <span class="n">dask</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">dask</span><span class="p">[</span><span class="n">dataframe</span><span class="p">]</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">ace_tools</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">optimize</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span> <span class="n">pyarrow</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">mglearn</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">statsmodels</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">imblearn</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">imbalanced</span><span class="o">-</span><span class="n">learn</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">bayesian</span><span class="o">-</span><span class="n">optimization</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)
Requirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.26.4)
Requirement already satisfied: scipy!=1.9.2,&gt;=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)
Requirement already satisfied: pandas!=2.1.0,&gt;=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.2)
Requirement already satisfied: patsy&gt;=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)
Requirement already satisfied: packaging&gt;=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.2)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)
Collecting sklearn
  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)
  <span class=" -Color -Color-Bold -Color-Bold-Red">error</span>: <span class=" -Color -Color-Bold">subprocess-exited-with-error</span>
  
  <span class=" -Color -Color-Red">×</span> <span class=" -Color -Color-Green">python setup.py egg_info</span> did not run successfully.
  <span class=" -Color -Color-Red">│</span> exit code: <span class=" -Color -Color-Bold -Color-Bold-Cyan">1</span>
  <span class=" -Color -Color-Red">╰─&gt;</span> See above for output.
  
  <span class=" -Color -Color-Bold -Color-Bold-Magenta">note</span>: This error originates from a subprocess, and is likely not a problem with pip.
  Preparing metadata (setup.py) ... ?25l?25herror
<span class=" -Color -Color-Bold -Color-Bold-Red">error</span>: <span class=" -Color -Color-Bold">metadata-generation-failed</span>

<span class=" -Color -Color-Red">×</span> Encountered error while generating package metadata.
<span class=" -Color -Color-Red">╰─&gt;</span> See above for output.

<span class=" -Color -Color-Bold -Color-Bold-Magenta">note</span>: This is an issue with the package mentioned above, not pip.
<span class=" -Color -Color-Bold -Color-Bold-Cyan">hint</span>: See above for details.
Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2024.10.0)
Requirement already satisfied: click&gt;=8.1 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.7)
Requirement already satisfied: cloudpickle&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask) (3.1.0)
Requirement already satisfied: fsspec&gt;=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2024.10.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (24.1)
Requirement already satisfied: partd&gt;=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.2)
Requirement already satisfied: pyyaml&gt;=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.2)
Requirement already satisfied: toolz&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.0.0)
Requirement already satisfied: importlib-metadata&gt;=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.5.0)
Requirement already satisfied: zipp&gt;=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata&gt;=4.13.0-&gt;dask) (3.20.2)
Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd&gt;=1.4.0-&gt;dask) (1.0.0)
Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)
Requirement already satisfied: missingno in /usr/local/lib/python3.10/dist-packages (0.5.2)
Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2024.10.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from missingno) (1.26.4)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from missingno) (3.7.1)
Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from missingno) (1.13.1)
Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from missingno) (0.13.2)
Requirement already satisfied: click&gt;=8.1 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.7)
Requirement already satisfied: cloudpickle&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask) (3.1.0)
Requirement already satisfied: fsspec&gt;=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2024.10.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (24.1)
Requirement already satisfied: partd&gt;=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.2)
Requirement already satisfied: pyyaml&gt;=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.2)
Requirement already satisfied: toolz&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.0.0)
Requirement already satisfied: importlib-metadata&gt;=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.5.0)
Requirement already satisfied: zipp&gt;=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata&gt;=4.13.0-&gt;dask) (3.20.2)
Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd&gt;=1.4.0-&gt;dask) (1.0.0)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;missingno) (1.3.0)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;missingno) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;missingno) (4.54.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;missingno) (1.4.7)
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;missingno) (11.0.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;missingno) (3.2.0)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;missingno) (2.9.0.post0)
Requirement already satisfied: pandas&gt;=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn-&gt;missingno) (2.2.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;missingno) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=1.2-&gt;seaborn-&gt;missingno) (2024.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;missingno) (1.16.0)
Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)
Requirement already satisfied: click&gt;=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)
Requirement already satisfied: cloudpickle&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)
Requirement already satisfied: fsspec&gt;=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.10.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.1)
Requirement already satisfied: partd&gt;=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)
Requirement already satisfied: pyyaml&gt;=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)
Requirement already satisfied: toolz&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.0.0)
Requirement already satisfied: importlib-metadata&gt;=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)
Requirement already satisfied: pandas&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)
Requirement already satisfied: dask-expr&lt;1.2,&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.1.16)
Requirement already satisfied: pyarrow&gt;=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr&lt;1.2,&gt;=1.1-&gt;dask[dataframe]) (17.0.0)
Requirement already satisfied: zipp&gt;=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata&gt;=4.13.0-&gt;dask[dataframe]) (3.20.2)
Requirement already satisfied: numpy&gt;=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=2.0-&gt;dask[dataframe]) (1.26.4)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=2.0-&gt;dask[dataframe]) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=2.0-&gt;dask[dataframe]) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=2.0-&gt;dask[dataframe]) (2024.2)
Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd&gt;=1.4.0-&gt;dask[dataframe]) (1.0.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&gt;=2.0-&gt;dask[dataframe]) (1.16.0)
Requirement already satisfied: ace_tools in /usr/local/lib/python3.10/dist-packages (0.0)
Collecting scikit-optimize
  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)
Collecting pyaml&gt;=16.9 (from scikit-optimize)
  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)
Requirement already satisfied: numpy&gt;=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)
Requirement already satisfied: scipy&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)
Requirement already satisfied: scikit-learn&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)
Requirement already satisfied: packaging&gt;=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)
Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml&gt;=16.9-&gt;scikit-optimize) (6.0.2)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&gt;=1.0.0-&gt;scikit-optimize) (3.5.0)
Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">107.8/107.8 kB</span> <span class=" -Color -Color-Red">3.0 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hDownloading pyaml-24.9.0-py3-none-any.whl (24 kB)
Installing collected packages: pyaml, scikit-optimize
Successfully installed pyaml-24.9.0 scikit-optimize-0.10.2
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)
Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)
Requirement already satisfied: numpy&gt;=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)
Collecting mglearn
  Downloading mglearn-0.2.0-py2.py3-none-any.whl.metadata (628 bytes)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.26.4)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mglearn) (3.7.1)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.5.2)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mglearn) (2.2.2)
Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from mglearn) (11.0.0)
Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from mglearn) (0.12.1)
Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from mglearn) (2.36.0)
Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mglearn) (1.4.2)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mglearn) (1.3.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mglearn) (4.54.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mglearn) (1.4.7)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mglearn) (24.1)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mglearn) (3.2.0)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mglearn) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;mglearn) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;mglearn) (2024.2)
Requirement already satisfied: scipy&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-&gt;mglearn) (1.13.1)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-&gt;mglearn) (3.5.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;mglearn) (1.16.0)
Downloading mglearn-0.2.0-py2.py3-none-any.whl (581 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">581.4/581.4 kB</span> <span class=" -Color -Color-Red">9.6 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hInstalling collected packages: mglearn
Successfully installed mglearn-0.2.0
Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)
Requirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.26.4)
Requirement already satisfied: scipy!=1.9.2,&gt;=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)
Requirement already satisfied: pandas!=2.1.0,&gt;=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.2)
Requirement already satisfied: patsy&gt;=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)
Requirement already satisfied: packaging&gt;=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.2)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)
Collecting imblearn
  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)
Collecting imbalanced-learn (from imblearn)
  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn-&gt;imblearn) (1.26.4)
Requirement already satisfied: scipy&gt;=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn-&gt;imblearn) (1.13.1)
Requirement already satisfied: scikit-learn&gt;=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn-&gt;imblearn) (1.5.2)
Requirement already satisfied: joblib&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn-&gt;imblearn) (1.4.2)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn-&gt;imblearn) (3.5.0)
Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)
Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">258.3/258.3 kB</span> <span class=" -Color -Color-Red">4.6 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hInstalling collected packages: imbalanced-learn, imblearn
Successfully installed imbalanced-learn-0.12.4 imblearn-0.0
Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)
Requirement already satisfied: scipy&gt;=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)
Requirement already satisfied: scikit-learn&gt;=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)
Requirement already satisfied: joblib&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)
Collecting bayesian-optimization
  Downloading bayesian_optimization-2.0.0-py3-none-any.whl.metadata (8.9 kB)
Collecting colorama&lt;0.5.0,&gt;=0.4.6 (from bayesian-optimization)
  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
Requirement already satisfied: numpy&gt;=1.25 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.26.4)
Requirement already satisfied: scikit-learn&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.5.2)
Requirement already satisfied: scipy&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.13.1)
Requirement already satisfied: joblib&gt;=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&lt;2.0.0,&gt;=1.0.0-&gt;bayesian-optimization) (1.4.2)
Requirement already satisfied: threadpoolctl&gt;=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&lt;2.0.0,&gt;=1.0.0-&gt;bayesian-optimization) (3.5.0)
Downloading bayesian_optimization-2.0.0-py3-none-any.whl (30 kB)
Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Installing collected packages: colorama, bayesian-optimization
Successfully installed bayesian-optimization-2.0.0 colorama-0.4.6
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span> <span class="c1">#Lectura de csv grandes</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">shapiro</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">normaltest</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">missingno</span> <span class="k">as</span> <span class="nn">msno</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">explained_variance_score</span><span class="p">,</span> <span class="n">mean_absolute_percentage_error</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MaxAbsScaler</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
<span class="kn">from</span> <span class="nn">plotly.subplots</span> <span class="kn">import</span> <span class="n">make_subplots</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span><span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span>
                             <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">ADASYN</span>
<span class="kn">from</span> <span class="nn">bayes_opt</span> <span class="kn">import</span> <span class="n">BayesianOptimization</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">ADASYN</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">chi2_contingency</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">kstest</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ruta donde guardaste los archivos en Google Drive</span>
<span class="n">input_dir</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/My Drive/&#39;</span>

<span class="c1"># Cargar los archivos CSV en DataFrames de pandas</span>
<span class="n">delinquency_imputed_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_dir</span> <span class="o">+</span> <span class="s1">&#39;delinquency_imputed_pd.csv&#39;</span><span class="p">)</span>
<span class="n">balance_imputed_filtered</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_dir</span> <span class="o">+</span> <span class="s1">&#39;balance_imputed_filtered.csv&#39;</span><span class="p">)</span>
<span class="n">risk_imputed_filtered</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_dir</span> <span class="o">+</span> <span class="s1">&#39;risk_imputed_filtered.csv&#39;</span><span class="p">)</span>
<span class="n">spend_imputed_filtered</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_dir</span> <span class="o">+</span> <span class="s1">&#39;spend_imputed_filtered.csv&#39;</span><span class="p">)</span>
<span class="n">payment_imputed_filtered</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_dir</span> <span class="o">+</span> <span class="s1">&#39;payment_imputed_filtered.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Concatenar los DataFrames</span>
<span class="n">final_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">delinquency_imputed_pd</span><span class="p">,</span> <span class="n">balance_imputed_filtered</span><span class="p">,</span> <span class="n">risk_imputed_filtered</span><span class="p">,</span>
                        <span class="n">spend_imputed_filtered</span><span class="p">,</span> <span class="n">payment_imputed_filtered</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">final_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">headers</span><span class="o">=</span><span class="s1">&#39;keys&#39;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;pretty&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+------------------------------------------------------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
|   |       D_105        |        D_56        |        D_77        |        D_43        |        D_46        |        D_62        |        D_48        |        D_61        |         D_78          |        D_44        |        D_83        |        D_69        |        D_55        |       D_124        |       D_119        |       D_118        |       D_115        |         D_113         |        D_125         |       D_121        |       D_122        |       D_123        |        D_91        |        D_59        |       D_141        |       D_131        |       D_139        |       D_145        |       D_130        |       D_129        |       D_103        |       D_107        |       D_104        |       D_143        |       D_128        |        D_70        |        D_79        |       D_133        |       D_144        |       D_102        |       D_140        |        D_84        |        D_89        |        D_52        |        D_81        |         D_72          |        D_74        |        D_80        |       D_112        |        D_45        |        D_54        |        D_41        |       D_109        |        D_47        |       D_127        |        D_92        |        D_93        |        D_94        |         D_65          |        D_86        |         D_96          |        D_58        |        D_60        |        D_51        |          D_75          |        D_71        |        D_39        |                           customer_ID                            | target |        B_13        |        B_8         |        B_25        |        B_15        |        B_3         |        B_22        |        B_16        |        B_20        |        B_19        |        B_26        |        B_33        |         B_27         |        B_41        |        B_6         |        B_40        |        B_4         |        B_5         |        B_10        |        B_7         |        B_28        |        B_36        |        B_11        |        B_12        |        B_9         |        B_24        |        B_21        |        B_32        |        R_27        |        R_20        |        R_7         |        R_14        |        R_2         |         R_21          |          R_22          |        R_23        |        R_24        |        R_25        |          R_17          |        R_18        |        R_13        |        R_15        |        R_16        |        R_10        |        R_11        |        R_6         |        R_8         |        R_4         |        R_3         |        R_28        |        R_19        |        S_9         |        S_27        |        S_7         |        S_24        |        S_26        |        S_23        |        S_5         |        S_15        |        S_18        |        S_11        |        S_16        |        S_17        |        S_6         |        S_12        |        S_8         |        S_13        |        S_19        |        S_20        |        P_3         |        P_2         |        P_4         |
+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+------------------------------------------------------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
| 0 | 0.8937341348828729 | 0.1520252359421985 | 0.2058334586674946 | 0.0885124453264733 | 0.3585865793715965 | 0.0910710227007408 | 0.255736073902975  | 0.3082332671932175 |  0.0015757362087887   | 0.0006301348049115 | 0.0070426005114811 | 0.0090132990688123 | 0.3545960121121521 |  0.68651647907618  | 0.236265664141208  | 0.232119945685299  | 0.2382502144880312 |  0.0078711392893406   |  0.0087397192234583  | 0.7022801580459578 | 0.4343448084924443 | 0.0030567005507437 | 1.5036730085591934 | 0.0636464650207709 | 0.0038178202065345 | 0.0059718815442907 | 0.0024270377979392 | 0.0026742140504133 | 0.0020516861203601 | 1.0000799619453766 | 1.0086908650957052 | 0.6700407818908409 | 1.0045868810535166 | 0.0005692395607335 | 1.007818575883756  | 0.0083417214056279 | 0.0042393583697225 | 0.0043450594318488 | 0.0006098370703087 | 0.766688198411884  | 0.0037062723407666 | 0.0008295199607458 | 0.0026653338683884 | 0.2073338786110817 | 0.0035319799108632 |  0.0048019001810845   | 0.080421566162112  | 0.0040605235125132 | 1.0073363113714342 | 0.708906305121159  | 1.0015189798143298 | 0.0087711319938824 | 0.0043255295479554 | 0.525351040810055  | 1.0033190016918123 | 1.0061334814309375 | 0.0035685409054337 | 0.0088705929060406 |  0.0071261626629251   | 0.0070844713819911 |  0.0049500294348479   | 0.1586119472568195 | 0.1996170060523628 | 1.3358557940752642 |   0.0690667888767042   | 0.1194032063292035 | 0.0017333390041739 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.1180751287426555 | 0.006465576798311  | 0.0077286495261238 | 0.0163605749523169 | 0.0047092406313857 | 0.0048075108615107 | 0.0076652663969786 | 0.0047298254668822 | 0.0085204395338161 | 0.0002718279749827 | 1.001101015728843  |  0.0023102973905819  | 0.0068049737160723 | 0.0639022133803909 | 0.2100604304228718 | 0.0809863324662527 | 0.1706002293387026 | 0.0962188066642168 | 0.0594157330614109 | 0.0846826103877939 | 0.0099684820571253 | 0.0027680616648439 | 0.1482660660500143 | 0.0082067391252636 | 0.0043267862651661 | 0.0026440261651032 | 0.0066261799942368 | 1.0089487592265078 | 0.0077815946151323 | 0.0075624451853513 | 0.0004379553773685 | 0.0062040314303209 |  0.0024499555060629   |   0.0074787553627031   | 0.0068928102215877 | 0.0039497309957728 | 0.0036471404974304 |   0.0001983075573362   | 0.0089074082880877 | 0.0038199826554652 | 0.0064516292630606 | 0.0050548740773288 | 0.0071210854061951 | 0.002456064794035  | 0.0083625394520617 | 0.0014339887242707 | 0.0082984353659013 | 0.0014225021561254 | 0.0015347274225173 | 0.0051773628715763 | 0.0657283519446441 | 0.6769221837463869 | 0.1613448213392926 | 0.911191467097734  | 0.0012434034603863 | 0.1355608144319887 | 0.0233811220509184 | 0.1082711171267683 | 0.0057204248912407 | 0.4016185802789523 | 0.0022709373260069 | 0.0080330227771146 | 0.0083216461012018 | 0.2720075971997457 | 0.9229980580065352 | 0.5152220997956324 | 0.0025372094454532 | 0.0097051381766323 | 0.7364627260945562 | 0.9384687191272548 | 0.0075544326681996 |
| 1 | 0.9068411206859838 | 0.1562009076504926 | 0.2058334586674946 | 0.0885124453264733 |  0.35362955018564  | 0.086804806253952  | 0.223328868696034  | 0.2650259667162577 |  0.0098958350711074   | 0.0025262722985727 | 0.0077893493218053 | 0.0078423846281866 | 0.3267569755070362 | 0.686414207300581  | 0.2418847785115039 | 0.243531650250564  | 0.2472173247423204 |  0.0034444037217743   |  0.0007550186621834  | 0.7070167405788484 | 0.4305006778687363 | 0.0013058529056339 | 1.503577287798595  | 0.0655014467923113 | 0.0050316339603931 | 0.0048375563132092 | 0.0039542127072645 | 0.0092168275029899 | 0.0010335637785626 | 1.0083440852188796 | 1.0000843809455782 | 0.6686470309941259 | 1.0041180541254393 | 0.0095764810309849 | 1.0043330167531577 | 0.0065238095494516 | 0.0075972844584575 | 0.0074947809621824 | 0.005492045139084  | 0.7860069250249836 | 0.0031670909399185 | 0.0094687918334821 | 0.0025076898346322 | 0.2027776508714612 | 0.0077727007757285 | 9.362862824238816e-05 | 0.0814131773985764 | 0.0001265094467791 | 1.007653237918183  | 0.7127947253698276 |  1.00903338642927  | 0.0007983594950325 | 0.0087072101387122 | 0.5213112572080865 | 1.0083943571051506 | 1.005791264255708  | 0.0005709012210667 | 0.0003907764310686 |  0.0024132392295972   | 0.0066773014785965 |  0.0031800843577881   | 0.1484594894825136 | 0.1513869942507153 | 1.3397939519002633 |   0.0741663611948242   | 0.1406107222744684 | 0.0057754430691282 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.1187374846997833 | 0.0016140100403202 | 0.0018641320957276 | 0.0176879271475391 |  0.00271357521442  | 0.0012831642549167 | 0.0071481629971447 | 0.0038792601718001 | 0.0022377908093277 | 0.0009788894238046 | 1.0067792074457678 |  0.001326726554301   | 0.0044071615620749 | 0.0652610579665619 | 0.1840927227397026 | 0.0694191902513324 | 0.1132386241994063 |  0.09980397147994  | 0.0577437664347247 | 0.0818432427851462 | 0.0039209972748469 | 0.0027493629604935 | 0.1435299034448566 | 0.0083732399772736 | 0.0042027572401495 | 0.0041931178334974 | 0.0018541096424292 | 1.0032054264726171 | 0.005987438457875  | 0.0053035174160201 | 0.0043108847373691 | 0.0062056675505455 |  0.0022468185583941   |   0.0068272696303746   | 0.002837081703293  | 0.0083512926195853 | 0.0088499705128094 |   0.0011422933789987   | 0.0059070092960333 | 0.0003466250884307 | 0.0023324956259801 | 0.0037531909670729 | 0.0059658070991361 | 0.0003953905325927 | 0.0040295733305978 | 0.0005093159076057 | 0.0051361761101383 | 0.0019844317102694 | 0.0049313627378137 | 0.0089791572797159 | 0.0939353797989685 | 0.8222809318522851 | 0.1409505240583456 | 0.9198763909178036 | 0.0045613841726178 | 0.1363325463457688 | 0.0305985529867176 | 0.1010183554793048 | 0.0075843411339787 | 0.4063261950481589 | 0.0098102293921389 | 0.0007604417997428 | 0.0024820657778834 | 0.188969661553206  |  0.91941367728506  | 0.509048176950083  |  0.00842719533128  | 0.0099237818960879 | 0.7208864251163005 | 0.9366646050988444 | 0.0048321739508196 |
| 2 | 0.9287193334883946 | 0.1537945530192474 | 0.2058334586674946 | 0.0885124453264733 | 0.3346501402648452 | 0.0940014256085902 | 0.1894239790446447 | 0.2121654193791872 |   0.009628574738144   | 0.0076047402985635 | 0.0040933640965983 | 0.0060252714539424 | 0.3041239914088586 | 0.6901005250292478 | 0.2397099509864065 | 0.2407679546576726 | 0.2398668653675786 |  0.0032691813363257   |  0.0096173897271883  | 0.7048432326890007 | 0.4344085049568127 | 0.0039543276434678 | 1.5033590471194136 | 0.0706065814012249 | 0.0004269179262986 | 0.0054966343952203 | 0.0032689906652928 | 0.0026032709011841 | 0.0056812210326452 | 1.006878112244593  | 1.0030135677143106 | 0.6709005074120858 | 1.0092849602930771 | 0.0034290796539485 | 1.007831058326676  | 0.0026147504927059 | 0.0030937702054758 | 0.0092266329541161 | 0.0069858016058412 | 0.8068400520912918 | 0.0073286547217627 | 0.0023248259483198 | 0.0096335585894785 | 0.2066290049015369 | 0.0088112235444419 |  0.0071515960821609   | 0.078890968759134  | 0.0009542544877357 | 1.0043123850971651 | 0.7208835908303046 | 1.0091837656946467 | 0.0075976139447434 | 0.0040919409275392 | 0.5245677277623807 | 1.0093065722557395 | 1.0058009320122954 | 0.0074254477549726 | 0.0092336003126575 |  0.0018780465076555   | 0.0011851157706375 |  0.0054334953218305   | 0.139503898583152  | 0.3058832414282441 | 1.3371789190649832 |   0.0765097917293057   | 0.0758679916967672 | 0.0915053967544593 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.1145342867500755 | 0.005125962010626  | 0.0054185349903392 | 0.0639548886316225 | 0.0094226602305931 | 0.0093926082125809 | 0.0036364946722024 | 0.004577810324232  | 0.0004076177206874 | 0.0061489030138677 | 1.0010139197036212 |  0.0076237460290023  | 0.003220698670307  | 0.0669819239633443 | 0.1548366496707575 | 0.0688388332731073 | 0.0604923316413934 | 0.1340731848894013 | 0.0566466868469979 | 0.0819537190655236 | 0.0012639841416997 | 0.0100772730979114 | 0.1370139429287773 | 0.0093545300907018 | 0.0017821196811741 | 0.001336558326951  | 0.0086863674258361 | 1.0007544990361332 | 0.0072906023804714 | 0.0014222286958287 | 0.007139482865085  | 0.0032591971425414 |  0.0077944529561709   |   0.0098201713043352   | 0.0050796651583663 | 0.0024712400793458 | 0.0097685447565016 |   0.0080129453149891   | 0.008882362868625  | 0.0027094594939989 | 0.0083580533673213 | 0.0073814599352351 | 0.005447101441569  | 0.0073453959600987 | 0.0068381543793031 | 0.008295195646472  | 0.0069612404755571 | 0.0074260928940361 | 0.0091226599087367 | 0.0020160558217114 | 0.0847569599479586 | 0.8534978657306381 | 0.1122294892642373 | 0.9586991459685772 | 0.0117355270245714 | 0.1349383150461293 | 0.0483669753740585 | 0.1032393766418472 | 0.0059008908273367 | 0.406768340897771  | 0.0093622848060888 | 0.0040561386734796 | 0.0005301333213372 | 0.4953084682104021 | 1.0019774050712138 | 0.6792567674570487 | 0.0073271789927629 | 0.0084459823340873 | 0.738044027559006  | 0.9541802771951844 | 0.0065607193283965 |
| 3 | 0.9353833481954704 | 0.1557724426811993 | 0.2058334586674946 | 0.0885124453264733 | 0.3232707585815574 | 0.0948544216699064 | 0.1355861611744148 | 0.2042997821821196 |  0.0085677316757374   | 0.0064059399174062 | 0.0088167902705024 | 0.0052706597774631 | 0.2750554000198449 | 0.6877793948325714 | 0.2407269867841221 | 0.2393996410996411 | 0.2409099063248252 | 5.320861293130253e-05 |  0.004648976640525   | 0.7115455766068481 | 0.4369025970518951 | 0.0051352360626393 | 1.5037014383836933 | 0.0659257343327038 | 0.003199977450383  | 0.0082607958684074 | 0.0061169427172603 | 0.0095999077113204 | 0.0071080800378311 | 1.0075725684462398 | 1.0015172165294348 | 0.6726196340902738 | 1.004514060187574  | 0.0084192219716654 | 1.0034604150978308 | 0.0020522972440974 | 0.0038952239757394 | 0.007205822824046  | 0.0065273044032599 | 0.8082136601563108 | 0.0045159294606539 | 0.005923557105094  | 0.0077906351559811 | 0.2082138520743839 | 0.0046519784203257 |  0.0053640447312242   | 0.0774903414141665 | 0.0056653253588366 | 1.0025384723833075 | 0.7239969737095179 | 1.0074555048039195 | 0.0006851772379011 | 0.0097034693879987 | 0.5309292044162731 | 1.001670673005053  | 1.0070358450082522 | 0.0006644696869961 |  0.00320016908277  |  0.0058985606582905   | 0.0033236101954835 | 6.291014462881938e-05 | 0.1381000038999483 | 0.2735528016469902 | 1.3399089237550763 |   0.0715473855043897   | 0.1502085208737178 | 0.0024552237550715 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.1207404693554312 | 0.0014175988102055 | 0.0006461846089433 | 0.0227322330992933 | 0.0055312417482453 | 0.0045544538491949 | 0.0058955953509557 | 0.0052074817815529 | 0.0058972186107103 |  0.00919323621371  | 1.0027746899406835 | 3.42411394943809e-05 | 0.0077032970653566 | 0.0837202553007994 | 0.1539388977512882 | 0.0556300137797556 | 0.1667822336735755 | 0.1344367157415507 | 0.0492529218010621 | 0.0606343675853891 | 0.0027293785235744 | 0.0096667670419601 | 0.1290167511713867 | 0.0067820950317783 | 0.0055950332150441 | 0.0087158177738176 | 0.0024779595418504 | 1.0053375978366663 | 0.0099765067824191 | 0.0063632046168579 | 0.0086897821324557 | 0.0099175321214759 |  0.0076859043033837   |   0.0004580691937654   | 0.007319748447642  | 0.0085065668770111 | 0.0048576693071139 |   0.0094545903195711   | 0.0083484527784619 | 0.0099822296178173 | 0.0073636794295889 | 0.0088023245016314 | 0.0018883740314669 | 0.0049611746997024 | 0.0081831091062062 | 0.0051528449766225 | 0.008705828970484  | 0.0035154716110688 | 0.0024089657352298 | 0.0039088398228798 | 0.0483821742935326 | 0.8446670029825571 | 0.1028376048044242 | 0.9263409246595956 | 0.0075706957813097 | 0.1400584257009597 | 0.030063455656396  | 0.2063939984106524 | 0.0025201677146212 | 0.4051752677805876 | 0.0048758610586565 | 0.0069692780197663 | 0.0007834045919221 | 0.5086702675540637 | 0.7040158269542894 | 0.5152816484179595 | 0.0070530669042235 | 0.0066143681011095 | 0.7418129623639812 | 0.9603835924391524 | 0.0095591194106795 |
| 4 | 0.9533625260792497 | 0.1549140301356253 | 0.2058334586674946 | 0.0885124453264733 | 0.2310086756150568 | 0.0939153362097016 | 0.2861716373869634 | 0.1756550577538386 |  0.0032890764131778   | 0.0077312593247709 | 0.001844613853006  | 0.0001520840860406 | 0.2311099531594969 | 0.6887740656266013 | 0.2423254206748976 | 0.2441992678137614 | 0.2479392090915889 |  0.0087238108017979   | 9.73447772624292e-05 | 0.7053434077038209 | 0.4374325704342859 | 0.0028487697381762 | 1.5099053428498577 | 0.063696550104271  | 0.0088889212072967 | 0.0048483059063966 | 0.0036714074296227 | 0.0098268553264915 | 0.0096804838824124 | 1.008132331984495  | 1.006125007878368  | 0.6738694561179293 | 1.0057350240016076 | 0.0016702960873798 | 1.0050527695002422 | 0.0014194918477125 | 0.0026079289859914 | 0.0063119013142961 | 0.008126328670533  | 0.8222811176179519 | 0.0049456665874077 | 0.0055160509318817 | 0.0051578264451005 | 0.2054675470560932 | 0.0011409508638597 |  0.0079724142388617   | 0.0765608473100266 | 0.0044645096574361 | 1.0001303394594476 | 0.7206190834139923 | 1.0037382346112425 | 0.004652640596536  | 0.0091202553344468 | 0.5293047211041928 | 1.0098857110582562 | 1.0029146817273296 | 0.0030785950738158 | 0.0038445131616787 |  0.0094791297286496   | 0.0015039733943202 |   0.000534921583544   | 0.1264430657144817 | 0.2331026038170543 | 1.3417354075370282 |    0.0744324202361     | 0.0964408087222197 | 0.0024830136942964 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.0951777983215747 | 0.0011986341650163 | 0.0018328273082353 | 0.0311706243993204 | 0.0093116076866038 | 0.0001037762306823 | 0.0017143546317675 | 0.0058507234966723 | 0.0077728937743949 | 0.0057381249379936 | 1.006536364130214  |  0.0021091750702607  | 0.009823431336813  | 0.0758999199008079 | 0.1207173795643496 | 0.038862084261875  | 0.1436304024238319 | 0.1215175529316183 | 0.0489179426307316 | 0.0624916569153162 | 0.0099983177612341 | 0.0094843762484197 | 0.1295387281849221 | 0.0005190923384714 | 0.004933211187413  | 0.0068213835917751 | 0.0021986212939474 | 1.0031749108531225 | 0.0041046679457298 | 0.0048309162890664 | 0.0078158931847375 | 0.0066673193692781 |  0.0096564037110082   |   0.0033412585017516   | 0.0002641683605526 | 0.0071903208754902 | 0.0029830029558698 |   0.0020185216679752   | 0.0026784197306769 | 0.0058599430226269 | 0.0024704359380366 | 0.0071664204885846 | 0.0061113294226629 | 0.0022464112394273 | 0.0086054937362035 | 0.0073376200775782 | 0.0038459171301568 | 0.0013615884419304 | 0.004462347796035  | 0.0034315578347587 | 0.0392592133700206 | 0.8111985865038022 | 0.0943108452151276 | 0.9334793735299338 | 0.0182003196690167 | 0.1316199205886922 | 0.0542211245490102 | 0.1060195346874305 | 0.0001551503504929 | 0.4874600745640535 | 0.0074467651639583 | 0.0017699229858768 | 0.0066976034283419 | 0.216506706011568  | 0.9171326748909656 | 0.5077123667592895 | 0.0077283433543811 | 0.005511345396912  | 0.6919863744155025 | 0.9472483832103192 | 0.0081557274909985 |
| 5 | 0.9671910460402964 | 0.1536470999342893 | 0.2058334586674946 | 0.0885124453264733 | 0.2759629064725732 | 0.0891374365239423 | 0.2861716373869634 | 0.1212760152032278 |  0.0024067932716935   | 0.0041284578196771 | 0.0042087078528436 | 0.0027877027313777 | 0.1879697469024532 | 0.6822967784780013 | 0.242621927267126  | 0.2442469856581007 | 0.2382602482014466 |  0.0095522525090564   |  0.0093047483309051  | 0.7112214436165599 | 0.4298859820538649 | 0.0032831279866011 | 1.0052074875817028 | 0.0422397801392449 | 0.0045292157691886 | 0.0007145533068556 | 0.0019242626056448 | 0.0028835818807404 | 0.0051506269987646 | 1.0084854471146127 | 1.0070855012261763 | 0.6731003461064419 | 1.011464453407426  | 0.000673555389663  | 1.0011160368134526 | 0.0077121250882518 | 0.0055502257063278 | 0.0029707694565871 | 0.0022227014282045 | 0.8433214640196395 | 0.0085981037497193 | 0.0096860294746539 | 0.0064722406934019 | 0.204167196773232  | 0.0048286359571861 |   0.000864998839374   | 0.0776833673549617 | 0.0074044328279625 | 1.0023453132440614 | 0.7213707569846346 | 1.0076038401946386 | 0.0098566327662354 | 0.007938039393906  | 0.5297616727419061 | 1.0044814615102493 | 1.0079945472141318 | 0.0052806399445665 | 0.0068296299358902 |  0.0022282666751793   | 0.0066883245701765 |  0.0098587681450707   | 0.103011316700751  | 0.3573466628560319 | 1.0005795362029424 |   0.0723674716666261   | 0.0937989338296096 | 0.0017457838458803 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.0977703902337396 | 0.0045774994055755 | 0.0095479123033482 | 0.0144390144154107 | 0.0098656795552509 | 0.0068394754621568 | 0.0011359930999324 | 0.0049964359600105 | 0.0061078068693318 | 0.0088922769441431 | 1.0071948327120337 |  0.0046206500958298  | 0.0047233742702148 | 0.0957843776472023 | 0.0829104173328858 | 0.0272647398656356 | 0.1383034859268958 | 0.1425636268359214 | 0.0357382849685497 | 0.0429720425583289 | 0.0014171992354624 | 0.0088774417101746 | 0.1209690186633742 | 0.0071233087497077 | 0.0010572257752109 | 0.0055415616082777 | 0.0062148581031788 | 1.0091075524586235 | 0.0051625861483969 | 0.0060757831746826 | 0.0087786127167275 | 0.0064368857678117 | 3.551399534273414e-05 |   0.0092327428549364   | 0.0006409536425795 | 0.0073016117358223 | 0.0042287210075297 | 2.1239054615119767e-05 | 0.0095156996042476 | 0.0045354736406055 | 0.0003109997264855 | 0.0091705718001955 | 0.0041606706278289 | 0.0006681795123028 | 0.0095943980219206 | 0.007194604155189  | 0.0024735232957268 | 0.007584591648045  | 0.0073287066818026 | 0.0048777876737166 | 0.0369065523083826 | 0.822321206393477  | 0.0935856891653906 | 0.9158768876664576 | 0.0270596761262122 | 0.1326634391962464 | 0.0097896764861365 | 0.108788836618391  | 0.0066297396114045 | 0.4826786282791208 | 0.0049153652552422 | 0.0073812238167987 | 0.0073760693830516 | 0.2155590674228304 | 0.9194467787965686 | 0.5109539489847503 | 0.0081685385199307 | 0.0007741609388042 | 0.6765282660256046 | 0.9459636118817272 | 0.0064827032665205 |
| 6 | 0.9916840162887576 | 0.1594381705168556 | 0.2058334586674946 | 0.0885124453264733 | 0.3078689359671168 | 0.0944357551446645 | 0.2861716373869634 | 0.3722664544447348 |  0.0064996054830825   | 0.0093967339886396 | 0.0078529523824342 | 0.0046226416313274 | 0.1482842649800371 | 0.6823677339309276 | 0.2442462560984613 | 0.245034347022337  | 0.2442064216774937 |  0.0074157108557422   |  0.0063466574243456  | 0.7166431300263268 | 0.4359143069004845 | 0.0092064410635425 | 1.0084330067221303 | 0.049150799880006  | 0.0093866980719847 | 0.0056529343955886 | 0.0013360692995636 | 0.0022246677584398 | 0.0021690183661893 | 1.0026575814567065 | 1.0089877170354402 | 0.6749324356156936 | 1.004514735262967  | 0.0077270284819473 | 1.0044163232639378 | 0.0010677026369865 | 0.0011601435046789 | 0.0083899510115469 | 0.0076608895878233 | 0.8635175169358612 | 0.0043607316196573 | 0.0024739133155108 | 0.0097186326347382 | 0.2080115384015178 | 0.0098469665747507 |  0.0041298474670294   | 0.0027580854749597 | 0.0028396043717553 | 1.0022697188028904 | 0.7217248001966956 | 1.0083258496680765 | 0.0066034111370398 | 0.009572797674357  | 0.5357474063779919 | 1.0023524965737438 |  1.00846904971251  | 0.0066391296863217 | 0.0050551856995062 |  0.0012340225708249   | 0.0087029815273651 |  0.0026536543599872   | 0.0013366639198223 | 1.0068016657385064 | 1.0016688875577835 |   0.0060000025531388   | 0.1371016610130062 |  0.00218293204105  | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.0922780276149574 | 0.0064237186068666 | 0.0075318424987806 | 0.0400021234456538 | 0.0007834780187052 | 0.0099523995641659 | 0.0078215452516202 | 0.0046725145522288 | 0.003034247913745  | 0.002695061085169  | 1.004926528119903  |  0.0024687375318003  | 0.0094901152069901 | 0.1045190784736111 | 0.0045423824983744 | 0.0066080347827099 | 0.1085215710887394 | 0.3160653066601654 | 0.0146723938820182 | 0.0149635537931305 | 0.0017356998605095 | 0.0027813599365764 | 0.1273837541716476 | 0.0082083423349938 | 0.0097197575472412 | 0.0083381168714978 | 0.0020851937826707 | 1.0082235832360569 | 0.0003699823918045 | 0.0082850965240349 | 0.0080814636742599 | 0.0022540269974671 |  0.0037885457413461   |   0.0089439249021257   | 0.0094481387890501 | 0.0070669175918328 | 0.0099300670775255 |   0.0086984169227309   | 0.0016716691211919 | 0.0030519010811696 | 0.0052014983939155 | 0.0002068907439411 | 0.0029208196261512 | 0.0076185746800033 | 0.0042647345433948 | 0.0099975435147691 | 0.0096514864750961 | 0.0044477174180475 | 0.0045173371317096 | 0.0092337083011324 | 0.0317293908121701 | 0.9063042441335566 | 0.0818046305956317 | 0.954676375296375  | 0.0221221413286521 | 0.1366687600010796 | 0.029674645963333  | 0.2026458081570316 | 0.008704918302749  | 0.4426235699721123 | 0.0039352904527686 | 0.002947474326499  | 0.0065225552509801 | 0.1887091025010536 | 0.7036019230864679 | 0.511999649795613  | 0.0071275729570493 | 0.0026314011589738 | 0.6801015522402724 | 0.9407046789164184 | 0.0040638732453734 |
| 7 | 0.9937350260227942 | 0.1619664693653038 | 0.2058334586674946 | 0.0885124453264733 | 0.5196185031637823 | 0.0944357551446645 | 0.2575692564377885 | 0.3722664544447348 |  0.0058432618642753   | 0.0013991274348094 | 0.0025884459899572 | 0.0007818941551659 | 0.1649497290961159 | 0.6871714217501913 | 0.2468524061290354 | 0.2396602643516106 | 0.2472844682268624 |  0.0020185289071703   |  0.0090987778647097  | 0.7079756038487348 | 0.4317405272493157 | 0.0004277573799743 | 1.0021692494162866 | 0.062682424455108  | 0.0055533958244812 | 0.0087131448667433 | 0.002396771670484  | 0.0073851388462432 | 0.0078231184416566 | 1.001262462308533  | 1.0016941967402728 | 0.6681310044536594 | 1.0122523099913534 | 0.0018314526325528 | 1.0081887458408874 | 0.0009588303083904 | 0.0087424713082865 | 0.000259180570594  | 0.0096160850118956 | 0.8669996872191166 | 0.0084523497839212 | 0.001969239852685  | 0.0070103085489723 | 0.2039552558058497 | 0.0070693265231773 |  0.0008140932358986   | 0.0057281946179136 | 0.0059223725875368 | 1.000371564458407  | 0.7232927236359844 |  1.00491957462695  | 0.0095266097150444 | 0.0072608176271738 | 0.5332947802727984 | 1.0058203927516982 | 0.0039363955443409 | 0.0034330386401161 | 0.0072483582715048 |  0.0034514809655168   | 0.007480879623354  |  0.0078561788498591   | 0.0052593573643354 | 1.0005235351838375 | 0.6712051396236316 | 3.6066530193548106e-05 | 0.1452038369587937 | 0.0030292790199935 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.0970513470521151 | 0.0008393410896402 | 0.0036510378490305 | 0.0188653882149632 | 0.0078362037526754 | 0.001275064819145  | 0.0026322932148366 | 0.0059783679261068 | 0.0043550827760548 | 0.0004697216708647 | 1.0000309814570485 |  0.0007757702488183  | 0.0065051651754028 | 0.1089262964086564 | 0.0097885074220518 | 0.0056772236455108 | 0.1876378270901438 | 0.3205691910288896 | 0.0059891695095165 | 0.0136531031837109 | 0.0056014651476094 | 0.0098446206766494 | 0.1232875946224534 | 0.0010772791238126 | 0.0004015509833063 | 0.0050274699303551 | 0.002415729256377  |  1.00831677211835  | 0.0025572544375144 | 0.0049588265596639 | 0.0021589914713823 | 0.0081544974812887 |  0.0019486486463775   |   0.0029944540736832   | 0.0081567825450059 | 0.0018379057097233 | 0.0014527117390126 |   0.0027100500851614   | 0.0025838528642308 | 0.0010488545602575 | 0.0060996094478308 | 0.0013761974503535 | 0.0021801896255154 | 0.0065425596950055 | 0.0055136650856945 | 0.0098413782264145 | 0.0074663603020378 | 0.007483517314337  | 0.0001387442839431 | 0.0037848873661869 | 0.0290529283040151 | 0.8357989879316553 | 0.0785755447987709 | 0.9192155804569916 | 0.0241641617360937 | 0.137489685249146  | 0.0220170695792881 | 0.2011206175043701 | 0.0043676660904675 | 0.4498340375014469 | 0.0013403562881626 | 0.0080005802648351 | 0.0084617135914764 | 0.1851948126096263 | 0.7551199261455626 | 0.6843135460408158 | 0.007441588646492  | 0.0086501485526394 | 0.6099957740422799 | 0.9147670493893196 | 0.0008853839349984 |
| 8 | 1.020660708166224  | 0.158126759265268  | 0.2058334586674946 | 0.0885124453264733 | 0.4300771846448445 | 0.0944357551446645 | 0.1893609224195585 | 0.1771252085325205 | 3.624275421044265e-05 | 0.002578465870261  | 0.007058289051388  | 0.004435944982039  | 0.160043504320865  | 0.6877147796769316 | 0.2443479825078859 | 0.2413414709530275 | 0.2498720958916638 |  0.0097236454192218   |  0.0002686565422236  | 0.7149366976456566 | 0.4336852810699584 | 0.0008307333808849 | 1.0036627204611257 | 0.0635340883598116 | 0.007944815165793  | 0.0072088142517259 | 0.0097423655303045 | 0.0009953430104718 | 0.0066518679916019 | 1.007012844716043  | 1.0071542233711848 | 0.6748030798422837 | 1.0080908623960374 | 0.0087215436033172 | 0.9995301392433436 | 0.0075355431300898 | 0.004471285975508  | 0.0004184615363164 | 0.0043693807876604 | 0.882474709592779  | 0.0039676574473463 | 0.0017265471257117 | 0.0022119417476376 | 0.2024021464973558 | 0.0046041610664292 |  0.0083398218846551   | 0.0092689016017333 | 0.2076388792498065 | 1.002789167664303  | 0.7309177958883605 | 1.0007210164964238 | 0.0025186576815874 | 0.0014597862685754 | 0.5390653557676703 | 1.009925203583362  | 0.0068727940282887 | 0.0057950452028664 | 0.0084777026675957 | 3.100893315078124e-05 | 0.0030323500667332 |  0.0036679925547943   | 0.000266583036556  | 1.009423639819606  | 0.6698005457348863 | 3.470137971787079e-05  | 0.2860142927282039 | 0.0098964257059747 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.0957671792317543 | 0.0048351569309309 | 0.0089770790184348 | 0.044197805366686  | 0.0098171777421018 | 0.0065095724820896 | 0.0035287537095216 | 0.005570065307398  | 0.0022903067899426 | 0.007846162871771  | 1.0028109448394866 |  0.0087028691307554  | 0.0099726693323038 | 0.1229280194706841 | 0.0075347855628422 | 0.0137129290186494 | 0.1785739485663343 | 0.3230324091352374 | 0.0173067412577464 | 0.024448123578749  | 0.0019237413408429 | 0.007466880320795  | 0.1213539900569882 | 0.0068221999152194 | 0.0072853130166155 | 0.0074615832752836 | 0.0085968023342541 | 1.0063904930885166 | 0.0030342539545122 | 0.005720466728536  | 0.0072454607057749 | 0.0098448601609722 |  0.0006603157040339   |   0.0049542159560828   | 0.0036944887281862 | 0.0062547168692986 | 0.0039794742367012 |   0.0085898332789385   | 0.0086843595257435 | 0.0004181764102252 | 0.0085527264034051 | 0.0030861432658919 | 0.0083392904158284 | 0.0036480122898861 | 0.0024429128201634 | 0.0019740038052015 | 0.009631852502275  | 0.0017268653030484 | 0.005737664655317  | 0.0039937782167094 | 0.0224438746746761 | 0.8110968784696331 | 0.0771956784033217 | 0.9505479861408248 | 0.0142535475055403 | 0.1360987043964827 | 0.0185068865148345 | 0.2084217362784136 | 0.0097138072850014 | 0.5664877588487857 | 0.0029215001109252 | 0.0016061080476243 | 0.0070167374001057 | 0.1583636363295984 | 0.7555118479269515 |  0.84712765946447  | 0.0004232790685359 | 0.0015023021615309 | 0.6976716789846967 | 0.9508447135239833 | 0.0037623069420786 |
| 9 | 1.0263303015928291 | 0.1612474292484877 | 0.2058334586674946 | 0.0885124453264733 | 0.430871390427649  | 0.0944357551446645 | 0.4034480139738597 | 0.1812905579949578 |  0.0083410925452883   | 0.0075953552804083 | 0.0056673233712434 | 0.005500163490587  | 0.1867658247141301 | 0.6832063180388467 | 0.2471269721480059 | 0.2515574277772331 | 0.2506120973214691 |  0.0033663820568347   |  0.0055130874844951  | 0.7151890624076328 | 0.4301193100478639 | 0.0022902569745168 | 1.0081610982649722 | 0.0711578578517557 | 0.0072660399641044 | 0.0075845379763578 | 0.003610790534134  | 0.0090683068825341 | 0.0049762953647572 | 1.005444651623414  | 1.0072429617618612 | 0.6730304614067126 | 1.0145486081108095 | 0.0087634320260678 | 1.008218712675853  | 0.0089740764429912 | 0.0056794674262166 | 0.0036730431555605 | 0.0047525067912037 | 0.9066990372686942 | 0.0096072896728455 | 0.0097633875907513 | 0.0080464812144459 | 0.2038070092868267 | 0.0038866526330526 |   0.009887591607121   | 0.0064783637642944 | 0.2051744633028546 | 1.0057005536427388 | 0.7350011535136693 | 1.009307483924488  | 0.0046256791375989 | 0.0059805343222304 | 0.5421190996915464 | 1.0024986355711956 | 0.0015551953718969 | 0.0094420807171814 | 0.0038268212941274 |  0.0011570568149075   | 0.003480258686309  |  0.0001145847642252   | 0.0049341572268211 | 1.0085337051582124 | 0.6683787727748051 |   0.0045401136371301   | 0.4309538003926637 | 0.0010823984401343 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a |   0    | 0.0748863687884937 | 0.0020896046685771 | 0.0037846437679275 | 0.0072193586206027 | 0.006073353287198  | 0.0089826278575187 | 0.0002267425485347 | 0.004406020475362  | 0.0048287169539765 | 0.0070103857320733 | 1.0014391560048344 |  0.0093847060791288  | 0.007171424492094  | 0.2218993716218757 | 0.0014036388504427 | 0.005182141460058  | 0.1890112787083474 | 0.4318644418945476 | 0.0016813085487004 | 0.0057426302583202 | 0.0070167870004832 | 0.0040265345294832 | 0.1125794971748788 | 0.007081370763396  | 0.007681156132543  | 0.0043295391236748 | 0.0058235415340103 | 1.0002456172305516 | 0.008906940108207  |  0.00670695345938  | 0.0058747194354147 | 0.0017952886145502 |  0.0099849242571557   | 1.4425055901404748e-05 | 0.0062576676843764 | 0.0029459354024003 | 0.0055453716760224 |   0.0043350311543925   | 0.0094000837202279 | 0.0095436339103418 | 0.0023758526521691 | 0.0023902987589964 | 0.003406901576585  | 0.0034140368711266 | 0.0051978839279686 | 0.0006291831884303 | 0.0061440044466796 | 0.0063691992035861 | 0.0012118532295288 | 0.0090162031673998 | 0.0193400963222388 | 0.8166506595347812 | 0.0746455602173381 | 0.9245174583391584 | 0.0227409505368596 | 0.1314544181243232 | 0.0071646631370205 | 0.200863298704696  | 0.0049310664729467 | 0.5686670277091231 | 0.0084278942631208 | 0.0063246593711757 | 0.0026287906488922 | 0.085942820812489  | 0.7594160228536814 | 0.8523926816420787 | 0.0074689960265172 | 0.0068314802135812 |  0.68988562282833  | 0.8685796264292405 | 0.0074551865612435 |
+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+------------------------------------------------------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">final_data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;D_105&#39;, &#39;D_56&#39;, &#39;D_77&#39;, &#39;D_43&#39;, &#39;D_46&#39;, &#39;D_62&#39;, &#39;D_48&#39;, &#39;D_61&#39;, &#39;D_78&#39;, &#39;D_44&#39;, &#39;D_83&#39;, &#39;D_69&#39;, &#39;D_55&#39;, &#39;D_124&#39;, &#39;D_119&#39;, &#39;D_118&#39;, &#39;D_115&#39;, &#39;D_113&#39;, &#39;D_125&#39;, &#39;D_121&#39;, &#39;D_122&#39;, &#39;D_123&#39;, &#39;D_91&#39;, &#39;D_59&#39;, &#39;D_141&#39;, &#39;D_131&#39;, &#39;D_139&#39;, &#39;D_145&#39;, &#39;D_130&#39;, &#39;D_129&#39;, &#39;D_103&#39;, &#39;D_107&#39;, &#39;D_104&#39;, &#39;D_143&#39;, &#39;D_128&#39;, &#39;D_70&#39;, &#39;D_79&#39;, &#39;D_133&#39;, &#39;D_144&#39;, &#39;D_102&#39;, &#39;D_140&#39;, &#39;D_84&#39;, &#39;D_89&#39;, &#39;D_52&#39;, &#39;D_81&#39;, &#39;D_72&#39;, &#39;D_74&#39;, &#39;D_80&#39;, &#39;D_112&#39;, &#39;D_45&#39;, &#39;D_54&#39;, &#39;D_41&#39;, &#39;D_109&#39;, &#39;D_47&#39;, &#39;D_127&#39;, &#39;D_92&#39;, &#39;D_93&#39;, &#39;D_94&#39;, &#39;D_65&#39;, &#39;D_86&#39;, &#39;D_96&#39;, &#39;D_58&#39;, &#39;D_60&#39;, &#39;D_51&#39;, &#39;D_75&#39;, &#39;D_71&#39;, &#39;D_39&#39;, &#39;customer_ID&#39;, &#39;target&#39;, &#39;B_13&#39;, &#39;B_8&#39;, &#39;B_25&#39;, &#39;B_15&#39;, &#39;B_3&#39;, &#39;B_22&#39;, &#39;B_16&#39;, &#39;B_20&#39;, &#39;B_19&#39;, &#39;B_26&#39;, &#39;B_33&#39;, &#39;B_27&#39;, &#39;B_41&#39;, &#39;B_6&#39;, &#39;B_40&#39;, &#39;B_4&#39;, &#39;B_5&#39;, &#39;B_10&#39;, &#39;B_7&#39;, &#39;B_28&#39;, &#39;B_36&#39;, &#39;B_11&#39;, &#39;B_12&#39;, &#39;B_9&#39;, &#39;B_24&#39;, &#39;B_21&#39;, &#39;B_32&#39;, &#39;R_27&#39;, &#39;R_20&#39;, &#39;R_7&#39;, &#39;R_14&#39;, &#39;R_2&#39;, &#39;R_21&#39;, &#39;R_22&#39;, &#39;R_23&#39;, &#39;R_24&#39;, &#39;R_25&#39;, &#39;R_17&#39;, &#39;R_18&#39;, &#39;R_13&#39;, &#39;R_15&#39;, &#39;R_16&#39;, &#39;R_10&#39;, &#39;R_11&#39;, &#39;R_6&#39;, &#39;R_8&#39;, &#39;R_4&#39;, &#39;R_3&#39;, &#39;R_28&#39;, &#39;R_19&#39;, &#39;S_9&#39;, &#39;S_27&#39;, &#39;S_7&#39;, &#39;S_24&#39;, &#39;S_26&#39;, &#39;S_23&#39;, &#39;S_5&#39;, &#39;S_15&#39;, &#39;S_18&#39;, &#39;S_11&#39;, &#39;S_16&#39;, &#39;S_17&#39;, &#39;S_6&#39;, &#39;S_12&#39;, &#39;S_8&#39;, &#39;S_13&#39;, &#39;S_19&#39;, &#39;S_20&#39;, &#39;P_3&#39;, &#39;P_2&#39;, &#39;P_4&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_feather</span><span class="p">(</span><span class="n">input_dir</span> <span class="o">+</span> <span class="s1">&#39;test_data.ftr&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Variables que deseas conservar en el DataFrame &#39;test&#39;</span>
<span class="n">columns_to_keep</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;D_105&#39;</span><span class="p">,</span> <span class="s1">&#39;D_56&#39;</span><span class="p">,</span> <span class="s1">&#39;D_77&#39;</span><span class="p">,</span> <span class="s1">&#39;D_43&#39;</span><span class="p">,</span> <span class="s1">&#39;D_46&#39;</span><span class="p">,</span> <span class="s1">&#39;D_62&#39;</span><span class="p">,</span> <span class="s1">&#39;D_48&#39;</span><span class="p">,</span> <span class="s1">&#39;D_61&#39;</span><span class="p">,</span> <span class="s1">&#39;D_78&#39;</span><span class="p">,</span>
    <span class="s1">&#39;D_44&#39;</span><span class="p">,</span> <span class="s1">&#39;D_83&#39;</span><span class="p">,</span> <span class="s1">&#39;D_69&#39;</span><span class="p">,</span> <span class="s1">&#39;D_55&#39;</span><span class="p">,</span> <span class="s1">&#39;D_124&#39;</span><span class="p">,</span> <span class="s1">&#39;D_119&#39;</span><span class="p">,</span> <span class="s1">&#39;D_118&#39;</span><span class="p">,</span> <span class="s1">&#39;D_115&#39;</span><span class="p">,</span> <span class="s1">&#39;D_113&#39;</span><span class="p">,</span>
    <span class="s1">&#39;D_125&#39;</span><span class="p">,</span> <span class="s1">&#39;D_121&#39;</span><span class="p">,</span> <span class="s1">&#39;D_122&#39;</span><span class="p">,</span> <span class="s1">&#39;D_123&#39;</span><span class="p">,</span> <span class="s1">&#39;D_91&#39;</span><span class="p">,</span> <span class="s1">&#39;D_59&#39;</span><span class="p">,</span> <span class="s1">&#39;D_141&#39;</span><span class="p">,</span> <span class="s1">&#39;D_131&#39;</span><span class="p">,</span>
    <span class="s1">&#39;D_139&#39;</span><span class="p">,</span> <span class="s1">&#39;D_145&#39;</span><span class="p">,</span> <span class="s1">&#39;D_130&#39;</span><span class="p">,</span> <span class="s1">&#39;D_129&#39;</span><span class="p">,</span> <span class="s1">&#39;D_103&#39;</span><span class="p">,</span> <span class="s1">&#39;D_107&#39;</span><span class="p">,</span> <span class="s1">&#39;D_104&#39;</span><span class="p">,</span> <span class="s1">&#39;D_143&#39;</span><span class="p">,</span>
    <span class="s1">&#39;D_128&#39;</span><span class="p">,</span> <span class="s1">&#39;D_70&#39;</span><span class="p">,</span> <span class="s1">&#39;D_79&#39;</span><span class="p">,</span> <span class="s1">&#39;D_133&#39;</span><span class="p">,</span> <span class="s1">&#39;D_144&#39;</span><span class="p">,</span> <span class="s1">&#39;D_102&#39;</span><span class="p">,</span> <span class="s1">&#39;D_140&#39;</span><span class="p">,</span> <span class="s1">&#39;D_84&#39;</span><span class="p">,</span>
    <span class="s1">&#39;D_89&#39;</span><span class="p">,</span> <span class="s1">&#39;D_52&#39;</span><span class="p">,</span> <span class="s1">&#39;D_81&#39;</span><span class="p">,</span> <span class="s1">&#39;D_72&#39;</span><span class="p">,</span> <span class="s1">&#39;D_74&#39;</span><span class="p">,</span> <span class="s1">&#39;D_80&#39;</span><span class="p">,</span> <span class="s1">&#39;D_112&#39;</span><span class="p">,</span> <span class="s1">&#39;D_45&#39;</span><span class="p">,</span> <span class="s1">&#39;D_54&#39;</span><span class="p">,</span>
    <span class="s1">&#39;D_41&#39;</span><span class="p">,</span> <span class="s1">&#39;D_109&#39;</span><span class="p">,</span> <span class="s1">&#39;D_47&#39;</span><span class="p">,</span> <span class="s1">&#39;D_127&#39;</span><span class="p">,</span> <span class="s1">&#39;D_92&#39;</span><span class="p">,</span> <span class="s1">&#39;D_93&#39;</span><span class="p">,</span> <span class="s1">&#39;D_94&#39;</span><span class="p">,</span> <span class="s1">&#39;D_65&#39;</span><span class="p">,</span> <span class="s1">&#39;D_86&#39;</span><span class="p">,</span>
    <span class="s1">&#39;D_96&#39;</span><span class="p">,</span> <span class="s1">&#39;D_58&#39;</span><span class="p">,</span> <span class="s1">&#39;D_60&#39;</span><span class="p">,</span> <span class="s1">&#39;D_51&#39;</span><span class="p">,</span> <span class="s1">&#39;D_75&#39;</span><span class="p">,</span> <span class="s1">&#39;D_71&#39;</span><span class="p">,</span> <span class="s1">&#39;D_39&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_ID&#39;</span><span class="p">,</span>
    <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;B_13&#39;</span><span class="p">,</span> <span class="s1">&#39;B_8&#39;</span><span class="p">,</span> <span class="s1">&#39;B_25&#39;</span><span class="p">,</span> <span class="s1">&#39;B_15&#39;</span><span class="p">,</span> <span class="s1">&#39;B_3&#39;</span><span class="p">,</span> <span class="s1">&#39;B_22&#39;</span><span class="p">,</span> <span class="s1">&#39;B_16&#39;</span><span class="p">,</span> <span class="s1">&#39;B_20&#39;</span><span class="p">,</span>
    <span class="s1">&#39;B_19&#39;</span><span class="p">,</span> <span class="s1">&#39;B_26&#39;</span><span class="p">,</span> <span class="s1">&#39;B_33&#39;</span><span class="p">,</span> <span class="s1">&#39;B_27&#39;</span><span class="p">,</span> <span class="s1">&#39;B_41&#39;</span><span class="p">,</span> <span class="s1">&#39;B_6&#39;</span><span class="p">,</span> <span class="s1">&#39;B_40&#39;</span><span class="p">,</span> <span class="s1">&#39;B_4&#39;</span><span class="p">,</span> <span class="s1">&#39;B_5&#39;</span><span class="p">,</span>
    <span class="s1">&#39;B_10&#39;</span><span class="p">,</span> <span class="s1">&#39;B_7&#39;</span><span class="p">,</span> <span class="s1">&#39;B_28&#39;</span><span class="p">,</span> <span class="s1">&#39;B_36&#39;</span><span class="p">,</span> <span class="s1">&#39;B_11&#39;</span><span class="p">,</span> <span class="s1">&#39;B_12&#39;</span><span class="p">,</span> <span class="s1">&#39;B_9&#39;</span><span class="p">,</span> <span class="s1">&#39;B_24&#39;</span><span class="p">,</span> <span class="s1">&#39;B_21&#39;</span><span class="p">,</span>
    <span class="s1">&#39;B_32&#39;</span><span class="p">,</span> <span class="s1">&#39;R_27&#39;</span><span class="p">,</span> <span class="s1">&#39;R_20&#39;</span><span class="p">,</span> <span class="s1">&#39;R_7&#39;</span><span class="p">,</span> <span class="s1">&#39;R_14&#39;</span><span class="p">,</span> <span class="s1">&#39;R_2&#39;</span><span class="p">,</span> <span class="s1">&#39;R_21&#39;</span><span class="p">,</span> <span class="s1">&#39;R_22&#39;</span><span class="p">,</span> <span class="s1">&#39;R_23&#39;</span><span class="p">,</span>
    <span class="s1">&#39;R_24&#39;</span><span class="p">,</span> <span class="s1">&#39;R_25&#39;</span><span class="p">,</span> <span class="s1">&#39;R_17&#39;</span><span class="p">,</span> <span class="s1">&#39;R_18&#39;</span><span class="p">,</span> <span class="s1">&#39;R_13&#39;</span><span class="p">,</span> <span class="s1">&#39;R_15&#39;</span><span class="p">,</span> <span class="s1">&#39;R_16&#39;</span><span class="p">,</span> <span class="s1">&#39;R_10&#39;</span><span class="p">,</span> <span class="s1">&#39;R_11&#39;</span><span class="p">,</span>
    <span class="s1">&#39;R_6&#39;</span><span class="p">,</span> <span class="s1">&#39;R_8&#39;</span><span class="p">,</span> <span class="s1">&#39;R_4&#39;</span><span class="p">,</span> <span class="s1">&#39;R_3&#39;</span><span class="p">,</span> <span class="s1">&#39;R_28&#39;</span><span class="p">,</span> <span class="s1">&#39;R_19&#39;</span><span class="p">,</span> <span class="s1">&#39;S_9&#39;</span><span class="p">,</span> <span class="s1">&#39;S_27&#39;</span><span class="p">,</span> <span class="s1">&#39;S_7&#39;</span><span class="p">,</span> <span class="s1">&#39;S_24&#39;</span><span class="p">,</span>
    <span class="s1">&#39;S_26&#39;</span><span class="p">,</span> <span class="s1">&#39;S_23&#39;</span><span class="p">,</span> <span class="s1">&#39;S_5&#39;</span><span class="p">,</span> <span class="s1">&#39;S_15&#39;</span><span class="p">,</span> <span class="s1">&#39;S_18&#39;</span><span class="p">,</span> <span class="s1">&#39;S_11&#39;</span><span class="p">,</span> <span class="s1">&#39;S_16&#39;</span><span class="p">,</span> <span class="s1">&#39;S_17&#39;</span><span class="p">,</span> <span class="s1">&#39;S_6&#39;</span><span class="p">,</span>
    <span class="s1">&#39;S_12&#39;</span><span class="p">,</span> <span class="s1">&#39;S_8&#39;</span><span class="p">,</span> <span class="s1">&#39;S_13&#39;</span><span class="p">,</span> <span class="s1">&#39;S_19&#39;</span><span class="p">,</span> <span class="s1">&#39;S_20&#39;</span><span class="p">,</span> <span class="s1">&#39;P_3&#39;</span><span class="p">,</span> <span class="s1">&#39;P_2&#39;</span><span class="p">,</span> <span class="s1">&#39;P_4&#39;</span>
<span class="p">]</span>

<span class="c1"># Filtrar el DataFrame para conservar solo las columnas deseadas</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">final_data</span><span class="p">[</span><span class="n">columns_to_keep</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Acomodar &#39;customer_ID&#39; como la primera columna</span>
<span class="n">cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="k">if</span> <span class="s1">&#39;customer_ID&#39;</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
    <span class="n">cols</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;customer_ID&#39;</span><span class="p">)</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;customer_ID&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">cols</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;La columna &#39;customer_ID&#39; no se encuentra en el conjunto de datos.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">headers</span><span class="o">=</span><span class="s1">&#39;keys&#39;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;pretty&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---+------------------------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
|   |                           customer_ID                            |       D_105        |        D_56        |        D_77        |        D_43        |        D_46        |        D_62        |        D_48        |        D_61        |         D_78          |        D_44        |        D_83        |        D_69        |        D_55        |       D_124        |       D_119        |       D_118        |       D_115        |         D_113         |        D_125         |       D_121        |       D_122        |       D_123        |        D_91        |        D_59        |       D_141        |       D_131        |       D_139        |       D_145        |       D_130        |       D_129        |       D_103        |       D_107        |       D_104        |       D_143        |       D_128        |        D_70        |        D_79        |       D_133        |       D_144        |       D_102        |       D_140        |        D_84        |        D_89        |        D_52        |        D_81        |         D_72          |        D_74        |        D_80        |       D_112        |        D_45        |        D_54        |        D_41        |       D_109        |        D_47        |       D_127        |        D_92        |        D_93        |        D_94        |         D_65          |        D_86        |         D_96          |        D_58        |        D_60        |        D_51        |          D_75          |        D_71        |        D_39        | target |        B_13        |        B_8         |        B_25        |        B_15        |        B_3         |        B_22        |        B_16        |        B_20        |        B_19        |        B_26        |        B_33        |         B_27         |        B_41        |        B_6         |        B_40        |        B_4         |        B_5         |        B_10        |        B_7         |        B_28        |        B_36        |        B_11        |        B_12        |        B_9         |        B_24        |        B_21        |        B_32        |        R_27        |        R_20        |        R_7         |        R_14        |        R_2         |         R_21          |          R_22          |        R_23        |        R_24        |        R_25        |          R_17          |        R_18        |        R_13        |        R_15        |        R_16        |        R_10        |        R_11        |        R_6         |        R_8         |        R_4         |        R_3         |        R_28        |        R_19        |        S_9         |        S_27        |        S_7         |        S_24        |        S_26        |        S_23        |        S_5         |        S_15        |        S_18        |        S_11        |        S_16        |        S_17        |        S_6         |        S_12        |        S_8         |        S_13        |        S_19        |        S_20        |        P_3         |        P_2         |        P_4         |
+---+------------------------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
| 0 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.8937341348828729 | 0.1520252359421985 | 0.2058334586674946 | 0.0885124453264733 | 0.3585865793715965 | 0.0910710227007408 | 0.255736073902975  | 0.3082332671932175 |  0.0015757362087887   | 0.0006301348049115 | 0.0070426005114811 | 0.0090132990688123 | 0.3545960121121521 |  0.68651647907618  | 0.236265664141208  | 0.232119945685299  | 0.2382502144880312 |  0.0078711392893406   |  0.0087397192234583  | 0.7022801580459578 | 0.4343448084924443 | 0.0030567005507437 | 1.5036730085591934 | 0.0636464650207709 | 0.0038178202065345 | 0.0059718815442907 | 0.0024270377979392 | 0.0026742140504133 | 0.0020516861203601 | 1.0000799619453766 | 1.0086908650957052 | 0.6700407818908409 | 1.0045868810535166 | 0.0005692395607335 | 1.007818575883756  | 0.0083417214056279 | 0.0042393583697225 | 0.0043450594318488 | 0.0006098370703087 | 0.766688198411884  | 0.0037062723407666 | 0.0008295199607458 | 0.0026653338683884 | 0.2073338786110817 | 0.0035319799108632 |  0.0048019001810845   | 0.080421566162112  | 0.0040605235125132 | 1.0073363113714342 | 0.708906305121159  | 1.0015189798143298 | 0.0087711319938824 | 0.0043255295479554 | 0.525351040810055  | 1.0033190016918123 | 1.0061334814309375 | 0.0035685409054337 | 0.0088705929060406 |  0.0071261626629251   | 0.0070844713819911 |  0.0049500294348479   | 0.1586119472568195 | 0.1996170060523628 | 1.3358557940752642 |   0.0690667888767042   | 0.1194032063292035 | 0.0017333390041739 |   0    | 0.1180751287426555 | 0.006465576798311  | 0.0077286495261238 | 0.0163605749523169 | 0.0047092406313857 | 0.0048075108615107 | 0.0076652663969786 | 0.0047298254668822 | 0.0085204395338161 | 0.0002718279749827 | 1.001101015728843  |  0.0023102973905819  | 0.0068049737160723 | 0.0639022133803909 | 0.2100604304228718 | 0.0809863324662527 | 0.1706002293387026 | 0.0962188066642168 | 0.0594157330614109 | 0.0846826103877939 | 0.0099684820571253 | 0.0027680616648439 | 0.1482660660500143 | 0.0082067391252636 | 0.0043267862651661 | 0.0026440261651032 | 0.0066261799942368 | 1.0089487592265078 | 0.0077815946151323 | 0.0075624451853513 | 0.0004379553773685 | 0.0062040314303209 |  0.0024499555060629   |   0.0074787553627031   | 0.0068928102215877 | 0.0039497309957728 | 0.0036471404974304 |   0.0001983075573362   | 0.0089074082880877 | 0.0038199826554652 | 0.0064516292630606 | 0.0050548740773288 | 0.0071210854061951 | 0.002456064794035  | 0.0083625394520617 | 0.0014339887242707 | 0.0082984353659013 | 0.0014225021561254 | 0.0015347274225173 | 0.0051773628715763 | 0.0657283519446441 | 0.6769221837463869 | 0.1613448213392926 | 0.911191467097734  | 0.0012434034603863 | 0.1355608144319887 | 0.0233811220509184 | 0.1082711171267683 | 0.0057204248912407 | 0.4016185802789523 | 0.0022709373260069 | 0.0080330227771146 | 0.0083216461012018 | 0.2720075971997457 | 0.9229980580065352 | 0.5152220997956324 | 0.0025372094454532 | 0.0097051381766323 | 0.7364627260945562 | 0.9384687191272548 | 0.0075544326681996 |
| 1 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.9068411206859838 | 0.1562009076504926 | 0.2058334586674946 | 0.0885124453264733 |  0.35362955018564  | 0.086804806253952  | 0.223328868696034  | 0.2650259667162577 |  0.0098958350711074   | 0.0025262722985727 | 0.0077893493218053 | 0.0078423846281866 | 0.3267569755070362 | 0.686414207300581  | 0.2418847785115039 | 0.243531650250564  | 0.2472173247423204 |  0.0034444037217743   |  0.0007550186621834  | 0.7070167405788484 | 0.4305006778687363 | 0.0013058529056339 | 1.503577287798595  | 0.0655014467923113 | 0.0050316339603931 | 0.0048375563132092 | 0.0039542127072645 | 0.0092168275029899 | 0.0010335637785626 | 1.0083440852188796 | 1.0000843809455782 | 0.6686470309941259 | 1.0041180541254393 | 0.0095764810309849 | 1.0043330167531577 | 0.0065238095494516 | 0.0075972844584575 | 0.0074947809621824 | 0.005492045139084  | 0.7860069250249836 | 0.0031670909399185 | 0.0094687918334821 | 0.0025076898346322 | 0.2027776508714612 | 0.0077727007757285 | 9.362862824238816e-05 | 0.0814131773985764 | 0.0001265094467791 | 1.007653237918183  | 0.7127947253698276 |  1.00903338642927  | 0.0007983594950325 | 0.0087072101387122 | 0.5213112572080865 | 1.0083943571051506 | 1.005791264255708  | 0.0005709012210667 | 0.0003907764310686 |  0.0024132392295972   | 0.0066773014785965 |  0.0031800843577881   | 0.1484594894825136 | 0.1513869942507153 | 1.3397939519002633 |   0.0741663611948242   | 0.1406107222744684 | 0.0057754430691282 |   0    | 0.1187374846997833 | 0.0016140100403202 | 0.0018641320957276 | 0.0176879271475391 |  0.00271357521442  | 0.0012831642549167 | 0.0071481629971447 | 0.0038792601718001 | 0.0022377908093277 | 0.0009788894238046 | 1.0067792074457678 |  0.001326726554301   | 0.0044071615620749 | 0.0652610579665619 | 0.1840927227397026 | 0.0694191902513324 | 0.1132386241994063 |  0.09980397147994  | 0.0577437664347247 | 0.0818432427851462 | 0.0039209972748469 | 0.0027493629604935 | 0.1435299034448566 | 0.0083732399772736 | 0.0042027572401495 | 0.0041931178334974 | 0.0018541096424292 | 1.0032054264726171 | 0.005987438457875  | 0.0053035174160201 | 0.0043108847373691 | 0.0062056675505455 |  0.0022468185583941   |   0.0068272696303746   | 0.002837081703293  | 0.0083512926195853 | 0.0088499705128094 |   0.0011422933789987   | 0.0059070092960333 | 0.0003466250884307 | 0.0023324956259801 | 0.0037531909670729 | 0.0059658070991361 | 0.0003953905325927 | 0.0040295733305978 | 0.0005093159076057 | 0.0051361761101383 | 0.0019844317102694 | 0.0049313627378137 | 0.0089791572797159 | 0.0939353797989685 | 0.8222809318522851 | 0.1409505240583456 | 0.9198763909178036 | 0.0045613841726178 | 0.1363325463457688 | 0.0305985529867176 | 0.1010183554793048 | 0.0075843411339787 | 0.4063261950481589 | 0.0098102293921389 | 0.0007604417997428 | 0.0024820657778834 | 0.188969661553206  |  0.91941367728506  | 0.509048176950083  |  0.00842719533128  | 0.0099237818960879 | 0.7208864251163005 | 0.9366646050988444 | 0.0048321739508196 |
| 2 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.9287193334883946 | 0.1537945530192474 | 0.2058334586674946 | 0.0885124453264733 | 0.3346501402648452 | 0.0940014256085902 | 0.1894239790446447 | 0.2121654193791872 |   0.009628574738144   | 0.0076047402985635 | 0.0040933640965983 | 0.0060252714539424 | 0.3041239914088586 | 0.6901005250292478 | 0.2397099509864065 | 0.2407679546576726 | 0.2398668653675786 |  0.0032691813363257   |  0.0096173897271883  | 0.7048432326890007 | 0.4344085049568127 | 0.0039543276434678 | 1.5033590471194136 | 0.0706065814012249 | 0.0004269179262986 | 0.0054966343952203 | 0.0032689906652928 | 0.0026032709011841 | 0.0056812210326452 | 1.006878112244593  | 1.0030135677143106 | 0.6709005074120858 | 1.0092849602930771 | 0.0034290796539485 | 1.007831058326676  | 0.0026147504927059 | 0.0030937702054758 | 0.0092266329541161 | 0.0069858016058412 | 0.8068400520912918 | 0.0073286547217627 | 0.0023248259483198 | 0.0096335585894785 | 0.2066290049015369 | 0.0088112235444419 |  0.0071515960821609   | 0.078890968759134  | 0.0009542544877357 | 1.0043123850971651 | 0.7208835908303046 | 1.0091837656946467 | 0.0075976139447434 | 0.0040919409275392 | 0.5245677277623807 | 1.0093065722557395 | 1.0058009320122954 | 0.0074254477549726 | 0.0092336003126575 |  0.0018780465076555   | 0.0011851157706375 |  0.0054334953218305   | 0.139503898583152  | 0.3058832414282441 | 1.3371789190649832 |   0.0765097917293057   | 0.0758679916967672 | 0.0915053967544593 |   0    | 0.1145342867500755 | 0.005125962010626  | 0.0054185349903392 | 0.0639548886316225 | 0.0094226602305931 | 0.0093926082125809 | 0.0036364946722024 | 0.004577810324232  | 0.0004076177206874 | 0.0061489030138677 | 1.0010139197036212 |  0.0076237460290023  | 0.003220698670307  | 0.0669819239633443 | 0.1548366496707575 | 0.0688388332731073 | 0.0604923316413934 | 0.1340731848894013 | 0.0566466868469979 | 0.0819537190655236 | 0.0012639841416997 | 0.0100772730979114 | 0.1370139429287773 | 0.0093545300907018 | 0.0017821196811741 | 0.001336558326951  | 0.0086863674258361 | 1.0007544990361332 | 0.0072906023804714 | 0.0014222286958287 | 0.007139482865085  | 0.0032591971425414 |  0.0077944529561709   |   0.0098201713043352   | 0.0050796651583663 | 0.0024712400793458 | 0.0097685447565016 |   0.0080129453149891   | 0.008882362868625  | 0.0027094594939989 | 0.0083580533673213 | 0.0073814599352351 | 0.005447101441569  | 0.0073453959600987 | 0.0068381543793031 | 0.008295195646472  | 0.0069612404755571 | 0.0074260928940361 | 0.0091226599087367 | 0.0020160558217114 | 0.0847569599479586 | 0.8534978657306381 | 0.1122294892642373 | 0.9586991459685772 | 0.0117355270245714 | 0.1349383150461293 | 0.0483669753740585 | 0.1032393766418472 | 0.0059008908273367 | 0.406768340897771  | 0.0093622848060888 | 0.0040561386734796 | 0.0005301333213372 | 0.4953084682104021 | 1.0019774050712138 | 0.6792567674570487 | 0.0073271789927629 | 0.0084459823340873 | 0.738044027559006  | 0.9541802771951844 | 0.0065607193283965 |
| 3 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.9353833481954704 | 0.1557724426811993 | 0.2058334586674946 | 0.0885124453264733 | 0.3232707585815574 | 0.0948544216699064 | 0.1355861611744148 | 0.2042997821821196 |  0.0085677316757374   | 0.0064059399174062 | 0.0088167902705024 | 0.0052706597774631 | 0.2750554000198449 | 0.6877793948325714 | 0.2407269867841221 | 0.2393996410996411 | 0.2409099063248252 | 5.320861293130253e-05 |  0.004648976640525   | 0.7115455766068481 | 0.4369025970518951 | 0.0051352360626393 | 1.5037014383836933 | 0.0659257343327038 | 0.003199977450383  | 0.0082607958684074 | 0.0061169427172603 | 0.0095999077113204 | 0.0071080800378311 | 1.0075725684462398 | 1.0015172165294348 | 0.6726196340902738 | 1.004514060187574  | 0.0084192219716654 | 1.0034604150978308 | 0.0020522972440974 | 0.0038952239757394 | 0.007205822824046  | 0.0065273044032599 | 0.8082136601563108 | 0.0045159294606539 | 0.005923557105094  | 0.0077906351559811 | 0.2082138520743839 | 0.0046519784203257 |  0.0053640447312242   | 0.0774903414141665 | 0.0056653253588366 | 1.0025384723833075 | 0.7239969737095179 | 1.0074555048039195 | 0.0006851772379011 | 0.0097034693879987 | 0.5309292044162731 | 1.001670673005053  | 1.0070358450082522 | 0.0006644696869961 |  0.00320016908277  |  0.0058985606582905   | 0.0033236101954835 | 6.291014462881938e-05 | 0.1381000038999483 | 0.2735528016469902 | 1.3399089237550763 |   0.0715473855043897   | 0.1502085208737178 | 0.0024552237550715 |   0    | 0.1207404693554312 | 0.0014175988102055 | 0.0006461846089433 | 0.0227322330992933 | 0.0055312417482453 | 0.0045544538491949 | 0.0058955953509557 | 0.0052074817815529 | 0.0058972186107103 |  0.00919323621371  | 1.0027746899406835 | 3.42411394943809e-05 | 0.0077032970653566 | 0.0837202553007994 | 0.1539388977512882 | 0.0556300137797556 | 0.1667822336735755 | 0.1344367157415507 | 0.0492529218010621 | 0.0606343675853891 | 0.0027293785235744 | 0.0096667670419601 | 0.1290167511713867 | 0.0067820950317783 | 0.0055950332150441 | 0.0087158177738176 | 0.0024779595418504 | 1.0053375978366663 | 0.0099765067824191 | 0.0063632046168579 | 0.0086897821324557 | 0.0099175321214759 |  0.0076859043033837   |   0.0004580691937654   | 0.007319748447642  | 0.0085065668770111 | 0.0048576693071139 |   0.0094545903195711   | 0.0083484527784619 | 0.0099822296178173 | 0.0073636794295889 | 0.0088023245016314 | 0.0018883740314669 | 0.0049611746997024 | 0.0081831091062062 | 0.0051528449766225 | 0.008705828970484  | 0.0035154716110688 | 0.0024089657352298 | 0.0039088398228798 | 0.0483821742935326 | 0.8446670029825571 | 0.1028376048044242 | 0.9263409246595956 | 0.0075706957813097 | 0.1400584257009597 | 0.030063455656396  | 0.2063939984106524 | 0.0025201677146212 | 0.4051752677805876 | 0.0048758610586565 | 0.0069692780197663 | 0.0007834045919221 | 0.5086702675540637 | 0.7040158269542894 | 0.5152816484179595 | 0.0070530669042235 | 0.0066143681011095 | 0.7418129623639812 | 0.9603835924391524 | 0.0095591194106795 |
| 4 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.9533625260792497 | 0.1549140301356253 | 0.2058334586674946 | 0.0885124453264733 | 0.2310086756150568 | 0.0939153362097016 | 0.2861716373869634 | 0.1756550577538386 |  0.0032890764131778   | 0.0077312593247709 | 0.001844613853006  | 0.0001520840860406 | 0.2311099531594969 | 0.6887740656266013 | 0.2423254206748976 | 0.2441992678137614 | 0.2479392090915889 |  0.0087238108017979   | 9.73447772624292e-05 | 0.7053434077038209 | 0.4374325704342859 | 0.0028487697381762 | 1.5099053428498577 | 0.063696550104271  | 0.0088889212072967 | 0.0048483059063966 | 0.0036714074296227 | 0.0098268553264915 | 0.0096804838824124 | 1.008132331984495  | 1.006125007878368  | 0.6738694561179293 | 1.0057350240016076 | 0.0016702960873798 | 1.0050527695002422 | 0.0014194918477125 | 0.0026079289859914 | 0.0063119013142961 | 0.008126328670533  | 0.8222811176179519 | 0.0049456665874077 | 0.0055160509318817 | 0.0051578264451005 | 0.2054675470560932 | 0.0011409508638597 |  0.0079724142388617   | 0.0765608473100266 | 0.0044645096574361 | 1.0001303394594476 | 0.7206190834139923 | 1.0037382346112425 | 0.004652640596536  | 0.0091202553344468 | 0.5293047211041928 | 1.0098857110582562 | 1.0029146817273296 | 0.0030785950738158 | 0.0038445131616787 |  0.0094791297286496   | 0.0015039733943202 |   0.000534921583544   | 0.1264430657144817 | 0.2331026038170543 | 1.3417354075370282 |    0.0744324202361     | 0.0964408087222197 | 0.0024830136942964 |   0    | 0.0951777983215747 | 0.0011986341650163 | 0.0018328273082353 | 0.0311706243993204 | 0.0093116076866038 | 0.0001037762306823 | 0.0017143546317675 | 0.0058507234966723 | 0.0077728937743949 | 0.0057381249379936 | 1.006536364130214  |  0.0021091750702607  | 0.009823431336813  | 0.0758999199008079 | 0.1207173795643496 | 0.038862084261875  | 0.1436304024238319 | 0.1215175529316183 | 0.0489179426307316 | 0.0624916569153162 | 0.0099983177612341 | 0.0094843762484197 | 0.1295387281849221 | 0.0005190923384714 | 0.004933211187413  | 0.0068213835917751 | 0.0021986212939474 | 1.0031749108531225 | 0.0041046679457298 | 0.0048309162890664 | 0.0078158931847375 | 0.0066673193692781 |  0.0096564037110082   |   0.0033412585017516   | 0.0002641683605526 | 0.0071903208754902 | 0.0029830029558698 |   0.0020185216679752   | 0.0026784197306769 | 0.0058599430226269 | 0.0024704359380366 | 0.0071664204885846 | 0.0061113294226629 | 0.0022464112394273 | 0.0086054937362035 | 0.0073376200775782 | 0.0038459171301568 | 0.0013615884419304 | 0.004462347796035  | 0.0034315578347587 | 0.0392592133700206 | 0.8111985865038022 | 0.0943108452151276 | 0.9334793735299338 | 0.0182003196690167 | 0.1316199205886922 | 0.0542211245490102 | 0.1060195346874305 | 0.0001551503504929 | 0.4874600745640535 | 0.0074467651639583 | 0.0017699229858768 | 0.0066976034283419 | 0.216506706011568  | 0.9171326748909656 | 0.5077123667592895 | 0.0077283433543811 | 0.005511345396912  | 0.6919863744155025 | 0.9472483832103192 | 0.0081557274909985 |
| 5 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.9671910460402964 | 0.1536470999342893 | 0.2058334586674946 | 0.0885124453264733 | 0.2759629064725732 | 0.0891374365239423 | 0.2861716373869634 | 0.1212760152032278 |  0.0024067932716935   | 0.0041284578196771 | 0.0042087078528436 | 0.0027877027313777 | 0.1879697469024532 | 0.6822967784780013 | 0.242621927267126  | 0.2442469856581007 | 0.2382602482014466 |  0.0095522525090564   |  0.0093047483309051  | 0.7112214436165599 | 0.4298859820538649 | 0.0032831279866011 | 1.0052074875817028 | 0.0422397801392449 | 0.0045292157691886 | 0.0007145533068556 | 0.0019242626056448 | 0.0028835818807404 | 0.0051506269987646 | 1.0084854471146127 | 1.0070855012261763 | 0.6731003461064419 | 1.011464453407426  | 0.000673555389663  | 1.0011160368134526 | 0.0077121250882518 | 0.0055502257063278 | 0.0029707694565871 | 0.0022227014282045 | 0.8433214640196395 | 0.0085981037497193 | 0.0096860294746539 | 0.0064722406934019 | 0.204167196773232  | 0.0048286359571861 |   0.000864998839374   | 0.0776833673549617 | 0.0074044328279625 | 1.0023453132440614 | 0.7213707569846346 | 1.0076038401946386 | 0.0098566327662354 | 0.007938039393906  | 0.5297616727419061 | 1.0044814615102493 | 1.0079945472141318 | 0.0052806399445665 | 0.0068296299358902 |  0.0022282666751793   | 0.0066883245701765 |  0.0098587681450707   | 0.103011316700751  | 0.3573466628560319 | 1.0005795362029424 |   0.0723674716666261   | 0.0937989338296096 | 0.0017457838458803 |   0    | 0.0977703902337396 | 0.0045774994055755 | 0.0095479123033482 | 0.0144390144154107 | 0.0098656795552509 | 0.0068394754621568 | 0.0011359930999324 | 0.0049964359600105 | 0.0061078068693318 | 0.0088922769441431 | 1.0071948327120337 |  0.0046206500958298  | 0.0047233742702148 | 0.0957843776472023 | 0.0829104173328858 | 0.0272647398656356 | 0.1383034859268958 | 0.1425636268359214 | 0.0357382849685497 | 0.0429720425583289 | 0.0014171992354624 | 0.0088774417101746 | 0.1209690186633742 | 0.0071233087497077 | 0.0010572257752109 | 0.0055415616082777 | 0.0062148581031788 | 1.0091075524586235 | 0.0051625861483969 | 0.0060757831746826 | 0.0087786127167275 | 0.0064368857678117 | 3.551399534273414e-05 |   0.0092327428549364   | 0.0006409536425795 | 0.0073016117358223 | 0.0042287210075297 | 2.1239054615119767e-05 | 0.0095156996042476 | 0.0045354736406055 | 0.0003109997264855 | 0.0091705718001955 | 0.0041606706278289 | 0.0006681795123028 | 0.0095943980219206 | 0.007194604155189  | 0.0024735232957268 | 0.007584591648045  | 0.0073287066818026 | 0.0048777876737166 | 0.0369065523083826 | 0.822321206393477  | 0.0935856891653906 | 0.9158768876664576 | 0.0270596761262122 | 0.1326634391962464 | 0.0097896764861365 | 0.108788836618391  | 0.0066297396114045 | 0.4826786282791208 | 0.0049153652552422 | 0.0073812238167987 | 0.0073760693830516 | 0.2155590674228304 | 0.9194467787965686 | 0.5109539489847503 | 0.0081685385199307 | 0.0007741609388042 | 0.6765282660256046 | 0.9459636118817272 | 0.0064827032665205 |
| 6 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.9916840162887576 | 0.1594381705168556 | 0.2058334586674946 | 0.0885124453264733 | 0.3078689359671168 | 0.0944357551446645 | 0.2861716373869634 | 0.3722664544447348 |  0.0064996054830825   | 0.0093967339886396 | 0.0078529523824342 | 0.0046226416313274 | 0.1482842649800371 | 0.6823677339309276 | 0.2442462560984613 | 0.245034347022337  | 0.2442064216774937 |  0.0074157108557422   |  0.0063466574243456  | 0.7166431300263268 | 0.4359143069004845 | 0.0092064410635425 | 1.0084330067221303 | 0.049150799880006  | 0.0093866980719847 | 0.0056529343955886 | 0.0013360692995636 | 0.0022246677584398 | 0.0021690183661893 | 1.0026575814567065 | 1.0089877170354402 | 0.6749324356156936 | 1.004514735262967  | 0.0077270284819473 | 1.0044163232639378 | 0.0010677026369865 | 0.0011601435046789 | 0.0083899510115469 | 0.0076608895878233 | 0.8635175169358612 | 0.0043607316196573 | 0.0024739133155108 | 0.0097186326347382 | 0.2080115384015178 | 0.0098469665747507 |  0.0041298474670294   | 0.0027580854749597 | 0.0028396043717553 | 1.0022697188028904 | 0.7217248001966956 | 1.0083258496680765 | 0.0066034111370398 | 0.009572797674357  | 0.5357474063779919 | 1.0023524965737438 |  1.00846904971251  | 0.0066391296863217 | 0.0050551856995062 |  0.0012340225708249   | 0.0087029815273651 |  0.0026536543599872   | 0.0013366639198223 | 1.0068016657385064 | 1.0016688875577835 |   0.0060000025531388   | 0.1371016610130062 |  0.00218293204105  |   0    | 0.0922780276149574 | 0.0064237186068666 | 0.0075318424987806 | 0.0400021234456538 | 0.0007834780187052 | 0.0099523995641659 | 0.0078215452516202 | 0.0046725145522288 | 0.003034247913745  | 0.002695061085169  | 1.004926528119903  |  0.0024687375318003  | 0.0094901152069901 | 0.1045190784736111 | 0.0045423824983744 | 0.0066080347827099 | 0.1085215710887394 | 0.3160653066601654 | 0.0146723938820182 | 0.0149635537931305 | 0.0017356998605095 | 0.0027813599365764 | 0.1273837541716476 | 0.0082083423349938 | 0.0097197575472412 | 0.0083381168714978 | 0.0020851937826707 | 1.0082235832360569 | 0.0003699823918045 | 0.0082850965240349 | 0.0080814636742599 | 0.0022540269974671 |  0.0037885457413461   |   0.0089439249021257   | 0.0094481387890501 | 0.0070669175918328 | 0.0099300670775255 |   0.0086984169227309   | 0.0016716691211919 | 0.0030519010811696 | 0.0052014983939155 | 0.0002068907439411 | 0.0029208196261512 | 0.0076185746800033 | 0.0042647345433948 | 0.0099975435147691 | 0.0096514864750961 | 0.0044477174180475 | 0.0045173371317096 | 0.0092337083011324 | 0.0317293908121701 | 0.9063042441335566 | 0.0818046305956317 | 0.954676375296375  | 0.0221221413286521 | 0.1366687600010796 | 0.029674645963333  | 0.2026458081570316 | 0.008704918302749  | 0.4426235699721123 | 0.0039352904527686 | 0.002947474326499  | 0.0065225552509801 | 0.1887091025010536 | 0.7036019230864679 | 0.511999649795613  | 0.0071275729570493 | 0.0026314011589738 | 0.6801015522402724 | 0.9407046789164184 | 0.0040638732453734 |
| 7 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 0.9937350260227942 | 0.1619664693653038 | 0.2058334586674946 | 0.0885124453264733 | 0.5196185031637823 | 0.0944357551446645 | 0.2575692564377885 | 0.3722664544447348 |  0.0058432618642753   | 0.0013991274348094 | 0.0025884459899572 | 0.0007818941551659 | 0.1649497290961159 | 0.6871714217501913 | 0.2468524061290354 | 0.2396602643516106 | 0.2472844682268624 |  0.0020185289071703   |  0.0090987778647097  | 0.7079756038487348 | 0.4317405272493157 | 0.0004277573799743 | 1.0021692494162866 | 0.062682424455108  | 0.0055533958244812 | 0.0087131448667433 | 0.002396771670484  | 0.0073851388462432 | 0.0078231184416566 | 1.001262462308533  | 1.0016941967402728 | 0.6681310044536594 | 1.0122523099913534 | 0.0018314526325528 | 1.0081887458408874 | 0.0009588303083904 | 0.0087424713082865 | 0.000259180570594  | 0.0096160850118956 | 0.8669996872191166 | 0.0084523497839212 | 0.001969239852685  | 0.0070103085489723 | 0.2039552558058497 | 0.0070693265231773 |  0.0008140932358986   | 0.0057281946179136 | 0.0059223725875368 | 1.000371564458407  | 0.7232927236359844 |  1.00491957462695  | 0.0095266097150444 | 0.0072608176271738 | 0.5332947802727984 | 1.0058203927516982 | 0.0039363955443409 | 0.0034330386401161 | 0.0072483582715048 |  0.0034514809655168   | 0.007480879623354  |  0.0078561788498591   | 0.0052593573643354 | 1.0005235351838375 | 0.6712051396236316 | 3.6066530193548106e-05 | 0.1452038369587937 | 0.0030292790199935 |   0    | 0.0970513470521151 | 0.0008393410896402 | 0.0036510378490305 | 0.0188653882149632 | 0.0078362037526754 | 0.001275064819145  | 0.0026322932148366 | 0.0059783679261068 | 0.0043550827760548 | 0.0004697216708647 | 1.0000309814570485 |  0.0007757702488183  | 0.0065051651754028 | 0.1089262964086564 | 0.0097885074220518 | 0.0056772236455108 | 0.1876378270901438 | 0.3205691910288896 | 0.0059891695095165 | 0.0136531031837109 | 0.0056014651476094 | 0.0098446206766494 | 0.1232875946224534 | 0.0010772791238126 | 0.0004015509833063 | 0.0050274699303551 | 0.002415729256377  |  1.00831677211835  | 0.0025572544375144 | 0.0049588265596639 | 0.0021589914713823 | 0.0081544974812887 |  0.0019486486463775   |   0.0029944540736832   | 0.0081567825450059 | 0.0018379057097233 | 0.0014527117390126 |   0.0027100500851614   | 0.0025838528642308 | 0.0010488545602575 | 0.0060996094478308 | 0.0013761974503535 | 0.0021801896255154 | 0.0065425596950055 | 0.0055136650856945 | 0.0098413782264145 | 0.0074663603020378 | 0.007483517314337  | 0.0001387442839431 | 0.0037848873661869 | 0.0290529283040151 | 0.8357989879316553 | 0.0785755447987709 | 0.9192155804569916 | 0.0241641617360937 | 0.137489685249146  | 0.0220170695792881 | 0.2011206175043701 | 0.0043676660904675 | 0.4498340375014469 | 0.0013403562881626 | 0.0080005802648351 | 0.0084617135914764 | 0.1851948126096263 | 0.7551199261455626 | 0.6843135460408158 | 0.007441588646492  | 0.0086501485526394 | 0.6099957740422799 | 0.9147670493893196 | 0.0008853839349984 |
| 8 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 1.020660708166224  | 0.158126759265268  | 0.2058334586674946 | 0.0885124453264733 | 0.4300771846448445 | 0.0944357551446645 | 0.1893609224195585 | 0.1771252085325205 | 3.624275421044265e-05 | 0.002578465870261  | 0.007058289051388  | 0.004435944982039  | 0.160043504320865  | 0.6877147796769316 | 0.2443479825078859 | 0.2413414709530275 | 0.2498720958916638 |  0.0097236454192218   |  0.0002686565422236  | 0.7149366976456566 | 0.4336852810699584 | 0.0008307333808849 | 1.0036627204611257 | 0.0635340883598116 | 0.007944815165793  | 0.0072088142517259 | 0.0097423655303045 | 0.0009953430104718 | 0.0066518679916019 | 1.007012844716043  | 1.0071542233711848 | 0.6748030798422837 | 1.0080908623960374 | 0.0087215436033172 | 0.9995301392433436 | 0.0075355431300898 | 0.004471285975508  | 0.0004184615363164 | 0.0043693807876604 | 0.882474709592779  | 0.0039676574473463 | 0.0017265471257117 | 0.0022119417476376 | 0.2024021464973558 | 0.0046041610664292 |  0.0083398218846551   | 0.0092689016017333 | 0.2076388792498065 | 1.002789167664303  | 0.7309177958883605 | 1.0007210164964238 | 0.0025186576815874 | 0.0014597862685754 | 0.5390653557676703 | 1.009925203583362  | 0.0068727940282887 | 0.0057950452028664 | 0.0084777026675957 | 3.100893315078124e-05 | 0.0030323500667332 |  0.0036679925547943   | 0.000266583036556  | 1.009423639819606  | 0.6698005457348863 | 3.470137971787079e-05  | 0.2860142927282039 | 0.0098964257059747 |   0    | 0.0957671792317543 | 0.0048351569309309 | 0.0089770790184348 | 0.044197805366686  | 0.0098171777421018 | 0.0065095724820896 | 0.0035287537095216 | 0.005570065307398  | 0.0022903067899426 | 0.007846162871771  | 1.0028109448394866 |  0.0087028691307554  | 0.0099726693323038 | 0.1229280194706841 | 0.0075347855628422 | 0.0137129290186494 | 0.1785739485663343 | 0.3230324091352374 | 0.0173067412577464 | 0.024448123578749  | 0.0019237413408429 | 0.007466880320795  | 0.1213539900569882 | 0.0068221999152194 | 0.0072853130166155 | 0.0074615832752836 | 0.0085968023342541 | 1.0063904930885166 | 0.0030342539545122 | 0.005720466728536  | 0.0072454607057749 | 0.0098448601609722 |  0.0006603157040339   |   0.0049542159560828   | 0.0036944887281862 | 0.0062547168692986 | 0.0039794742367012 |   0.0085898332789385   | 0.0086843595257435 | 0.0004181764102252 | 0.0085527264034051 | 0.0030861432658919 | 0.0083392904158284 | 0.0036480122898861 | 0.0024429128201634 | 0.0019740038052015 | 0.009631852502275  | 0.0017268653030484 | 0.005737664655317  | 0.0039937782167094 | 0.0224438746746761 | 0.8110968784696331 | 0.0771956784033217 | 0.9505479861408248 | 0.0142535475055403 | 0.1360987043964827 | 0.0185068865148345 | 0.2084217362784136 | 0.0097138072850014 | 0.5664877588487857 | 0.0029215001109252 | 0.0016061080476243 | 0.0070167374001057 | 0.1583636363295984 | 0.7555118479269515 |  0.84712765946447  | 0.0004232790685359 | 0.0015023021615309 | 0.6976716789846967 | 0.9508447135239833 | 0.0037623069420786 |
| 9 | 0000099d6bd597052cdcda90ffabf56573fe9d7c79be5fbac11a8ed792feb62a | 1.0263303015928291 | 0.1612474292484877 | 0.2058334586674946 | 0.0885124453264733 | 0.430871390427649  | 0.0944357551446645 | 0.4034480139738597 | 0.1812905579949578 |  0.0083410925452883   | 0.0075953552804083 | 0.0056673233712434 | 0.005500163490587  | 0.1867658247141301 | 0.6832063180388467 | 0.2471269721480059 | 0.2515574277772331 | 0.2506120973214691 |  0.0033663820568347   |  0.0055130874844951  | 0.7151890624076328 | 0.4301193100478639 | 0.0022902569745168 | 1.0081610982649722 | 0.0711578578517557 | 0.0072660399641044 | 0.0075845379763578 | 0.003610790534134  | 0.0090683068825341 | 0.0049762953647572 | 1.005444651623414  | 1.0072429617618612 | 0.6730304614067126 | 1.0145486081108095 | 0.0087634320260678 | 1.008218712675853  | 0.0089740764429912 | 0.0056794674262166 | 0.0036730431555605 | 0.0047525067912037 | 0.9066990372686942 | 0.0096072896728455 | 0.0097633875907513 | 0.0080464812144459 | 0.2038070092868267 | 0.0038866526330526 |   0.009887591607121   | 0.0064783637642944 | 0.2051744633028546 | 1.0057005536427388 | 0.7350011535136693 | 1.009307483924488  | 0.0046256791375989 | 0.0059805343222304 | 0.5421190996915464 | 1.0024986355711956 | 0.0015551953718969 | 0.0094420807171814 | 0.0038268212941274 |  0.0011570568149075   | 0.003480258686309  |  0.0001145847642252   | 0.0049341572268211 | 1.0085337051582124 | 0.6683787727748051 |   0.0045401136371301   | 0.4309538003926637 | 0.0010823984401343 |   0    | 0.0748863687884937 | 0.0020896046685771 | 0.0037846437679275 | 0.0072193586206027 | 0.006073353287198  | 0.0089826278575187 | 0.0002267425485347 | 0.004406020475362  | 0.0048287169539765 | 0.0070103857320733 | 1.0014391560048344 |  0.0093847060791288  | 0.007171424492094  | 0.2218993716218757 | 0.0014036388504427 | 0.005182141460058  | 0.1890112787083474 | 0.4318644418945476 | 0.0016813085487004 | 0.0057426302583202 | 0.0070167870004832 | 0.0040265345294832 | 0.1125794971748788 | 0.007081370763396  | 0.007681156132543  | 0.0043295391236748 | 0.0058235415340103 | 1.0002456172305516 | 0.008906940108207  |  0.00670695345938  | 0.0058747194354147 | 0.0017952886145502 |  0.0099849242571557   | 1.4425055901404748e-05 | 0.0062576676843764 | 0.0029459354024003 | 0.0055453716760224 |   0.0043350311543925   | 0.0094000837202279 | 0.0095436339103418 | 0.0023758526521691 | 0.0023902987589964 | 0.003406901576585  | 0.0034140368711266 | 0.0051978839279686 | 0.0006291831884303 | 0.0061440044466796 | 0.0063691992035861 | 0.0012118532295288 | 0.0090162031673998 | 0.0193400963222388 | 0.8166506595347812 | 0.0746455602173381 | 0.9245174583391584 | 0.0227409505368596 | 0.1314544181243232 | 0.0071646631370205 | 0.200863298704696  | 0.0049310664729467 | 0.5686670277091231 | 0.0084278942631208 | 0.0063246593711757 | 0.0026287906488922 | 0.085942820812489  | 0.7594160228536814 | 0.8523926816420787 | 0.0074689960265172 | 0.0068314802135812 |  0.68988562282833  | 0.8685796264292405 | 0.0074551865612435 |
+---+------------------------------------------------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+------------------------+--------------------+--------------------+--------------------+------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="s1">&#39;target&#39;</span> <span class="ow">in</span> <span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_ID&#39;</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;La columna &#39;target&#39; no se encuentra en el conjunto de datos.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="codificacion-de-variables-categoricas">
<h1>Codificación de variables categóricas<a class="headerlink" href="#codificacion-de-variables-categoricas" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Codificación de variables categóricas</span>
<span class="n">categorical_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;B_30&#39;</span><span class="p">,</span> <span class="s1">&#39;B_38&#39;</span><span class="p">,</span> <span class="s1">&#39;D_114&#39;</span><span class="p">,</span> <span class="s1">&#39;D_116&#39;</span><span class="p">,</span> <span class="s1">&#39;D_117&#39;</span><span class="p">,</span> <span class="s1">&#39;D_120&#39;</span><span class="p">,</span> <span class="s1">&#39;D_126&#39;</span><span class="p">,</span> <span class="s1">&#39;D_63&#39;</span><span class="p">,</span> <span class="s1">&#39;D_64&#39;</span><span class="p">,</span> <span class="s1">&#39;D_66&#39;</span><span class="p">,</span> <span class="s1">&#39;D_68&#39;</span><span class="p">]</span>

<span class="c1"># Verificar qué variables categóricas están presentes en el DataFrame test</span>
<span class="n">existing_categorical_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">categorical_vars</span> <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="c1"># Convertir las variables categóricas existentes a tipo &#39;category&#39; (opcional)</span>
<span class="n">X</span><span class="p">[</span><span class="n">existing_categorical_vars</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">existing_categorical_vars</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

<span class="c1"># Aplicar One-Hot Encoding a las variables categóricas existentes</span>
<span class="n">X_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">existing_categorical_vars</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Verificar que todas las columnas sean numéricas</span>
<span class="n">non_numeric_cols</span> <span class="o">=</span> <span class="n">X_encoded</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">non_numeric_cols</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Las siguientes columnas no son numéricas y deben ser codificadas: </span><span class="si">{</span><span class="n">non_numeric_cols</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dividir el conjunto de datos en entrenamiento y prueba</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_encoded</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Codificación de variables categóricas</span>
<span class="n">categorical_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;B_30&#39;</span><span class="p">,</span> <span class="s1">&#39;B_38&#39;</span><span class="p">,</span> <span class="s1">&#39;D_114&#39;</span><span class="p">,</span> <span class="s1">&#39;D_116&#39;</span><span class="p">,</span> <span class="s1">&#39;D_117&#39;</span><span class="p">,</span> <span class="s1">&#39;D_120&#39;</span><span class="p">,</span> <span class="s1">&#39;D_126&#39;</span><span class="p">,</span> <span class="s1">&#39;D_63&#39;</span><span class="p">,</span> <span class="s1">&#39;D_64&#39;</span><span class="p">,</span> <span class="s1">&#39;D_66&#39;</span><span class="p">,</span> <span class="s1">&#39;D_68&#39;</span><span class="p">]</span>

<span class="c1"># Verificar qué variables categóricas están presentes en el DataFrame test</span>
<span class="n">existing_categorical_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">categorical_vars</span> <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="c1"># Convertir las variables categóricas existentes a tipo &#39;category&#39; (opcional)</span>
<span class="n">test</span><span class="p">[</span><span class="n">existing_categorical_vars</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">existing_categorical_vars</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Aplicar One-Hot Encoding a las variables categóricas existentes</span>
<span class="n">X_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">existing_categorical_vars</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X_encoded</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_encoded</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="definicion-de-metricas">
<h1>Definición de métricas<a class="headerlink" href="#definicion-de-metricas" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span>

<span class="c1"># Definición de métricas personalizadas</span>
<span class="k">def</span> <span class="nf">top_four_percent_captured</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;prediction&#39;</span><span class="p">:</span> <span class="n">y_pred_proba</span><span class="p">})</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;prediction&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">20</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">four_pct_cutoff</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.04</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight_cumsum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>
    <span class="n">df_cutoff</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight_cumsum&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">four_pct_cutoff</span><span class="p">]</span>
    <span class="n">D</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_cutoff</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">D</span>

<span class="k">def</span> <span class="nf">weighted_gini</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;prediction&#39;</span><span class="p">:</span> <span class="n">y_pred_proba</span><span class="p">})</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;prediction&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">20</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;random&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>
    <span class="n">total_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cum_pos_found&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lorentz&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cum_pos_found&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_pos</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;lorentz&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;random&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">G</span>

<span class="k">def</span> <span class="nf">normalized_weighted_gini</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;prediction&#39;</span><span class="p">:</span> <span class="n">y_pred_proba</span><span class="p">})</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">weighted_gini</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span>
    <span class="n">G_max</span> <span class="o">=</span> <span class="n">weighted_gini</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">G</span> <span class="o">/</span> <span class="n">G_max</span>

<span class="k">def</span> <span class="nf">defaultprob_metric</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">):</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">normalized_weighted_gini</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">top_four_percent_captured</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">G</span> <span class="o">+</span> <span class="n">D</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">M</span>

<span class="c1"># Funciones para visualización</span>
<span class="k">def</span> <span class="nf">plot_confusion</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Etiqueta Verdadera&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Etiqueta Predicha&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_roc_curve_custom</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="exploracion-inicial-de-variable-respuesta">
<h1>Exploración inicial de variable respuesta<a class="headerlink" href="#exploracion-inicial-de-variable-respuesta" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">final_data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Frecuencia de Valores&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Valor&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frecuencia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/18b5e5019e6ef2bd0efaae52dd5e2d29edf31d0983660d519911243bc691a2f5.png" src="_images/18b5e5019e6ef2bd0efaae52dd5e2d29edf31d0983660d519911243bc691a2f5.png" />
</div>
</div>
</section>
<section id="modelo-con-adasyn">
<h1>Modelo con ADASYN<a class="headerlink" href="#modelo-con-adasyn" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">adasyn</span> <span class="o">=</span> <span class="n">ADASYN</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">start_time_adasyn</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">X_train_adasyn</span><span class="p">,</span> <span class="n">y_train_adasyn</span> <span class="o">=</span> <span class="n">adasyn</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">end_time_adasyn</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">adasyn_time</span> <span class="o">=</span> <span class="n">end_time_adasyn</span> <span class="o">-</span> <span class="n">start_time_adasyn</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Distribución de clases antes de ADASYN:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribución de clases después de ADASYN:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_train_adasyn</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tiempo de ejecución de ADASYN: </span><span class="si">{</span><span class="n">adasyn_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> segundos&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inicializar diccionario para almacenar resultados</span>
<span class="n">results_adasyn</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Modelo&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;F1-Score&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;AUC&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;Tiempo_ejecucion(seg)&#39;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p>Clasificación bayesiana</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">start_time_gnb</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_adasyn</span><span class="p">,</span> <span class="n">y_train_adasyn</span><span class="p">)</span>
<span class="n">end_time_gnb</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">gnb_time</span> <span class="o">=</span> <span class="n">end_time_gnb</span> <span class="o">-</span> <span class="n">start_time_gnb</span>

<span class="n">y_pred_proba_gnb</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred_gnb</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">precision_gnb</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_gnb</span><span class="p">)</span>
<span class="n">recall_gnb</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_gnb</span><span class="p">)</span>
<span class="n">f1_gnb</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_gnb</span><span class="p">)</span>
<span class="n">auc_gnb</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_gnb</span><span class="p">)</span>
<span class="n">M_gnb</span> <span class="o">=</span> <span class="n">defaultprob_metric</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_gnb</span><span class="p">)</span>

<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Modelo&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;Clasificación Bayesiana ADASYN&#39;</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Precision&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_gnb</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Recall&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_gnb</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;F1-Score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_gnb</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;AUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc_gnb</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">M_gnb</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Tiempo_ejecucion(seg)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gnb_time</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Modelo K-NN</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">start_time_knn</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_adasyn</span><span class="p">,</span> <span class="n">y_train_adasyn</span><span class="p">)</span>
<span class="n">end_time_knn</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">knn_time</span> <span class="o">=</span> <span class="n">end_time_knn</span> <span class="o">-</span> <span class="n">start_time_knn</span>

<span class="n">y_pred_proba_knn</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred_knn</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">precision_knn</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">)</span>
<span class="n">recall_knn</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">)</span>
<span class="n">f1_knn</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">)</span>
<span class="n">auc_knn</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_knn</span><span class="p">)</span>
<span class="n">M_knn</span> <span class="o">=</span> <span class="n">defaultprob_metric</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_knn</span><span class="p">)</span>

<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Modelo&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;K-NN ADASYN&#39;</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Precision&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_knn</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Recall&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_knn</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;F1-Score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_knn</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;AUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc_knn</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">M_knn</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Tiempo_ejecucion(seg)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn_time</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Logística L2</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">start_time_lr_l2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">logreg_l2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">logreg_l2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_adasyn</span><span class="p">,</span> <span class="n">y_train_adasyn</span><span class="p">)</span>
<span class="n">end_time_lr_l2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">lr_l2_time</span> <span class="o">=</span> <span class="n">end_time_lr_l2</span> <span class="o">-</span> <span class="n">start_time_lr_l2</span>

<span class="n">y_pred_proba_lr_l2</span> <span class="o">=</span> <span class="n">logreg_l2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred_lr_l2</span> <span class="o">=</span> <span class="n">logreg_l2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">precision_lr_l2</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr_l2</span><span class="p">)</span>
<span class="n">recall_lr_l2</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr_l2</span><span class="p">)</span>
<span class="n">f1_lr_l2</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr_l2</span><span class="p">)</span>
<span class="n">auc_lr_l2</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_lr_l2</span><span class="p">)</span>
<span class="n">M_lr_l2</span> <span class="o">=</span> <span class="n">defaultprob_metric</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_lr_l2</span><span class="p">)</span>

<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Modelo&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;Regresión Logística L2 ADASYN&#39;</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Precision&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_lr_l2</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Recall&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_lr_l2</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;F1-Score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_lr_l2</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;AUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc_lr_l2</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">M_lr_l2</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Tiempo_ejecucion(seg)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr_l2_time</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Logística L1</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">start_time_lr_l1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">logreg_l1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">logreg_l1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_adasyn</span><span class="p">,</span> <span class="n">y_train_adasyn</span><span class="p">)</span>
<span class="n">end_time_lr_l1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">lr_l1_time</span> <span class="o">=</span> <span class="n">end_time_lr_l1</span> <span class="o">-</span> <span class="n">start_time_lr_l1</span>

<span class="n">y_pred_proba_lr_l1</span> <span class="o">=</span> <span class="n">logreg_l1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred_lr_l1</span> <span class="o">=</span> <span class="n">logreg_l1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">precision_lr_l1</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr_l1</span><span class="p">)</span>
<span class="n">recall_lr_l1</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr_l1</span><span class="p">)</span>
<span class="n">f1_lr_l1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr_l1</span><span class="p">)</span>
<span class="n">auc_lr_l1</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_lr_l1</span><span class="p">)</span>
<span class="n">M_lr_l1</span> <span class="o">=</span> <span class="n">defaultprob_metric</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba_lr_l1</span><span class="p">)</span>

<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Modelo&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;Regresión Logística L1 ADASYN&#39;</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Precision&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision_lr_l1</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Recall&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_lr_l1</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;F1-Score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_lr_l1</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;AUC&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">auc_lr_l1</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">M_lr_l1</span><span class="p">)</span>
<span class="n">results_adasyn</span><span class="p">[</span><span class="s1">&#39;Tiempo_ejecucion(seg)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lr_l1_time</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelamiento-sin-adasyn">
<h1>Modelamiento sin Adasyn<a class="headerlink" href="#modelamiento-sin-adasyn" title="Link to this heading">#</a></h1>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Ejercicio3.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Ejercicio 3</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Codificación de variables categóricas</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-de-metricas">Definición de métricas</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#exploracion-inicial-de-variable-respuesta">Exploración inicial de variable respuesta</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-con-adasyn">Modelo con ADASYN</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelamiento-sin-adasyn">Modelamiento sin Adasyn</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kelly Beltran y Henry Saenz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>